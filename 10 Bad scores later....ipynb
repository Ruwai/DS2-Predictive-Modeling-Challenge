{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrislouie/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import warnings\n",
    "import category_encoders as ce\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression,f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 40), (14358, 40), (59400, 2), (14358, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = pd.read_csv('train_features.csv')\n",
    "test_features = pd.read_csv('test_features.csv')\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "train_features.shape, test_features.shape, train_labels.shape, sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_mean = train[train['construction_year']>0]['construction_year'].mean()\n",
    "year_mean = round(year_mean)\n",
    "\n",
    "test_year_mean = test_features[test_features['construction_year']>0]['construction_year'].mean()\n",
    "test_year_mean = round(test_year_mean)\n",
    "\n",
    "\n",
    "train.loc[train['construction_year']==0, 'construction_year'] = int(year_mean)\n",
    "test_features.loc[test_features['construction_year']==0,'construction_year'] = int(test_year_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_std(year):\n",
    "    \n",
    "    std = year - random.randint(-10,10)\n",
    "    \n",
    "    return std    \n",
    "\n",
    "def random_tsh(amount):\n",
    "    \n",
    "    std = amount + np.random.uniform(1062.35, 2957.82)\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tsh_mean = train[train['amount_tsh']>0]['amount_tsh'].mean()\n",
    "test_tsh_mean = test_features[test_features['amount_tsh']>0]['amount_tsh'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 40), (14358, 40))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train['construction_year']==1997, 'construction_year'].apply(random_std)\n",
    "test_features.loc[test_features['construction_year']==1997, 'construction_year'].apply(random_std)\n",
    "train.loc[train['amount_tsh']==0, 'amount_tsh'] = train_tsh_mean\n",
    "test_features.loc[test_features['amount_tsh']==0, 'amount_tsh'] = test_tsh_mean\n",
    "\n",
    "train.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['funder'].fillna('?',inplace=True)\n",
    "train['installer'].fillna('?',inplace=True)\n",
    "train['subvillage'].fillna('?',inplace=True)\n",
    "train['public_meeting'].fillna('?',inplace=True)\n",
    "train['scheme_management'].fillna('?',inplace=True)\n",
    "train['scheme_name'].fillna('?',inplace=True)\n",
    "train['permit'].fillna('?',inplace=True)\n",
    "test_features['funder'].fillna('?',inplace=True)\n",
    "test_features['installer'].fillna('?',inplace=True)\n",
    "test_features['subvillage'].fillna('?',inplace=True)\n",
    "test_features['public_meeting'].fillna('?',inplace=True)\n",
    "test_features['scheme_management'].fillna('?',inplace=True)\n",
    "test_features['scheme_name'].fillna('?',inplace=True)\n",
    "test_features['permit'].fillna('?',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['age'] = (2019 - train['construction_year']).astype(int)\n",
    "test_features['age'] = (2019 - test_features['construction_year']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vwc', 'wug', 'other', 'private operator', 'water board', 'wua',\n",
       "       'company', 'water authority', 'parastatal', 'unknown',\n",
       "       'other - school', 'trust'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['management'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 20, 21, 90, 18,  4, 17, 14, 60, 10,  3, 15, 19, 16, 80,  1,  6,\n",
       "        2, 12, 13,  5,  7, 99, 24,  9,  8, 40])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['region_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['date_recorded'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train['date_recorded'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_days_since = np.array(train['date_recorded'].values, dtype='datetime64')\n",
    "test_days_since = np.array(test_features['date_recorded'].values,dtype='datetime64')\n",
    "\n",
    "train_birth = train['construction_year'].astype(str)\n",
    "test_birth = test_features['construction_year'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years_since = np.datetime_as_string(train_days_since, unit='Y')\n",
    "test_years_since = np.datetime_as_string(test_days_since, unit='Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59400"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_years_since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14358"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_years_since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years_since = train_years_since.astype(int)\n",
    "test_years_since = test_years_since.astype(int)\n",
    "train_birth = train_birth.astype(int)\n",
    "test_birth = test_birth.astype(int)\n",
    "\n",
    "in_train_years = []\n",
    "in_test_years = []\n",
    "\n",
    "for i in range(0,len(train_years_since)):\n",
    "    x = train_years_since[i] - train_birth[i]\n",
    "    in_train_years.append(x)\n",
    "    \n",
    "\n",
    "for i in range(0,len(test_years_since)):\n",
    "    x = test_years_since[i] - test_birth[i]\n",
    "    in_test_years.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['years_until_record'] = in_train_years\n",
    "test_features['years_until_record'] = in_test_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 22), (14358, 22))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_these=[\n",
    "    'date_recorded',\n",
    "    'wpt_name',\n",
    "    'recorded_by',\n",
    "    'lga',\n",
    "    'ward',\n",
    "    'scheme_name', \n",
    "    'scheme_management',\n",
    "    'funder',\n",
    "    'installer',\n",
    "    'num_private',\n",
    "    'subvillage',\n",
    "    'basin',\n",
    "    'longitude',\n",
    "    'latitude',\n",
    "    'region',\n",
    "    'waterpoint_type_group',\n",
    "    'extraction_type_group',\n",
    "    'extraction_type_class',\n",
    "    'management_group', \n",
    "]\n",
    "train.drop(columns=drop_these,inplace=True)\n",
    "test_features.drop(columns=drop_these,inplace=True)\n",
    "\n",
    "train.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 109), (14358, 108))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = ce.OneHotEncoder(use_cat_names=True,handle_unknown='ignore',impute_missing=False)\n",
    "\n",
    "train_features = ohe.fit_transform(train)\n",
    "test_features = ohe.fit_transform(test_features)\n",
    "\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction_type_other - mkulima/shinyanga\n"
     ]
    }
   ],
   "source": [
    "columns = train_features.columns\n",
    "test_cols = test_features.columns\n",
    "for col in columns:\n",
    "    if col not in test_cols:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.drop(columns=['extraction_type_other - mkulima/shinyanga'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_features\n",
    "X_test = test_features\n",
    "y_train = train_labels['status_group']\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = make_pipeline(\n",
    "#     StandardScaler(),\n",
    "#     SelectKBest(f_classif),\n",
    "#     LogisticRegression()\n",
    "# )\n",
    "\n",
    "# param_grid = {\n",
    "#     'selectkbest__k': range(1,X_train.shape[1]+1),\n",
    "#     'logisticregression__solver':['lbfgs'],\n",
    "#     'logisticregression__multi_class':['multinomial'],\n",
    "#     'logisticregression__warm_start':[True],\n",
    "#     'logisticregression__max_iter':[500,1000,1500],\n",
    "#     'logisticregression__class_weight':[None, 'balanced'],\n",
    "#     'logisticregression__random_state':[42,101,369]\n",
    "# }\n",
    "\n",
    "# gridsearch = GridSearchCV(pipeline, param_grid = param_grid, cv=5, \n",
    "#                           scoring='accuracy', iid=False, verbose=10,\n",
    "#                           refit=True)\n",
    "# gridsearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gridsearch.best_estimator_)\n",
    "# print(gridsearch.best_score_)\n",
    "# print(gridsearch.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission=sample_submission.copy()\n",
    "# submission['status_group'] = gridsearch.predict(X_test)\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv('submission-015.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_features\n",
    "X_test = test_features\n",
    "y_train = train_labels['status_group']\n",
    "scaler = RobustScaler()\n",
    "X_train = X_train.drop(columns='id')\n",
    "X_test = X_test.drop(columns='id')\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'multiclass',\n",
    "          'num_leaves': 42,\n",
    "          'learning_rate': 0.01,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 100000,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 2,\n",
    "          'reg_lambda': 5,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 25,\n",
    "          'num_class' : 3,\n",
    "          'metric' : 'multi_logloss'}\n",
    "\n",
    "model = lgb.LGBMClassifier(\n",
    "    boosting_type = 'gbdt',\n",
    "    objective = 'multiclass',\n",
    "    n_jobs = -1,\n",
    "    max_depth = params['max_depth'],\n",
    "    max_bin = params['max_bin'],\n",
    "    subsample_for_bin = params['subsample_for_bin'],\n",
    "    subsample = params['subsample'],\n",
    "    subsample_freq = params['subsample_freq'],\n",
    "    min_split_gain = params['min_split_gain'],\n",
    "    min_child_weight = params['min_child_weight'],\n",
    "    min_child_samples = params['min_child_samples'],\n",
    "    \n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'boosting_type': ['gbdt', 'dart'],\n",
    "    'learning_rate': [0.001,0.01],\n",
    "    'num_iterations': [1000,2000],\n",
    "    'num_leaves': [100,200],\n",
    "    'min_child_samples': [25,50],\n",
    "    'max_bin': [200000],    \n",
    "    'reg_alpha': [1.2],\n",
    "    'reg_lambda': [1.2],\n",
    "    'min_split_gain': [0.5]\n",
    "}\n",
    "# hopefully this works lol\n",
    "gridsearch = GridSearchCV(model, param_grid = param_grid,\n",
    "                          verbose=1,cv=3,n_jobs=,scoring='accuracy')\n",
    "\n",
    "gridsearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrislouie/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  50785      functional\n",
       "1  51630      functional\n",
       "2  17168      functional\n",
       "3  45559  non functional\n",
       "4  49871      functional"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=sample_submission.copy()\n",
    "submission['status_group'] = gridsearch.predict(X_test)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission-016.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['public_meeting_True', 'public_meeting_?', 'public_meeting_False',\n",
       "       'permit_False', 'permit_True', 'permit_?', 'management_vwc',\n",
       "       'management_wug', 'management_other', 'management_private operator',\n",
       "       'management_water board', 'management_wua', 'management_company',\n",
       "       'management_water authority', 'management_parastatal',\n",
       "       'management_unknown', 'management_other - school', 'management_trust',\n",
       "       'management_group_user-group', 'management_group_other',\n",
       "       'management_group_commercial', 'management_group_parastatal',\n",
       "       'management_group_unknown', 'payment_pay annually', 'payment_never pay',\n",
       "       'payment_pay per bucket', 'payment_unknown',\n",
       "       'payment_pay when scheme fails', 'payment_other', 'payment_pay monthly',\n",
       "       'payment_type_annually', 'payment_type_never pay',\n",
       "       'payment_type_per bucket', 'payment_type_unknown',\n",
       "       'payment_type_on failure', 'payment_type_other', 'payment_type_monthly',\n",
       "       'water_quality_soft', 'water_quality_salty', 'water_quality_milky',\n",
       "       'water_quality_unknown', 'water_quality_fluoride',\n",
       "       'water_quality_coloured', 'water_quality_salty abandoned',\n",
       "       'water_quality_fluoride abandoned', 'quality_group_good',\n",
       "       'quality_group_salty', 'quality_group_milky', 'quality_group_unknown',\n",
       "       'quality_group_fluoride', 'quality_group_colored', 'quantity_enough',\n",
       "       'quantity_insufficient', 'quantity_dry', 'quantity_seasonal',\n",
       "       'quantity_unknown', 'quantity_group_enough',\n",
       "       'quantity_group_insufficient', 'quantity_group_dry',\n",
       "       'quantity_group_seasonal', 'quantity_group_unknown', 'source_spring',\n",
       "       'source_rainwater harvesting', 'source_dam', 'source_machine dbh',\n",
       "       'source_other', 'source_shallow well', 'source_river',\n",
       "       'source_hand dtw', 'source_lake', 'source_unknown',\n",
       "       'source_type_spring', 'source_type_rainwater harvesting',\n",
       "       'source_type_dam', 'source_type_borehole', 'source_type_other',\n",
       "       'source_type_shallow well', 'source_type_river/lake',\n",
       "       'source_class_groundwater', 'source_class_surface',\n",
       "       'source_class_unknown', 'waterpoint_type_communal standpipe',\n",
       "       'waterpoint_type_communal standpipe multiple',\n",
       "       'waterpoint_type_hand pump', 'waterpoint_type_other',\n",
       "       'waterpoint_type_improved spring', 'waterpoint_type_cattle trough',\n",
       "       'waterpoint_type_dam', 'id', 'amount_tsh', 'gps_height', 'region_code',\n",
       "       'district_code', 'population', 'construction_year', 'age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = RobustScaler()\n",
    "# scaler.fit(train_features)\n",
    "# X_train = scaler.transform(train_features)\n",
    "# X_test = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = make_pipeline(\n",
    "#     DecisionTreeClassifier()\n",
    "# )\n",
    "# param_grid={\n",
    "#     'decisiontreeclassifier__criterion': ['gini'], \n",
    "#     'decisiontreeclassifier__min_samples_split': [20,30,40],\n",
    "#     'decisiontreeclassifier__max_depth': [25,50,100],\n",
    "#     'decisiontreeclassifier__min_samples_leaf': [3,5,7]\n",
    "# }\n",
    "\n",
    "# gridsearch = GridSearchCV(pipeline,param_grid=param_grid,cv=5,scoring='neg_mean_absolute_error',\n",
    "#                           verbose=1,return_train_score=True)\n",
    "\n",
    "# gridsearch.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  50785      functional\n",
       "1  51630      functional\n",
       "2  17168      functional\n",
       "3  45559  non functional\n",
       "4  49871      functional"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "scaler.fit(train_features)\n",
    "X_train = scaler.transform(train_features)\n",
    "model = RandomForestClassifier()\n",
    "model.set_params(n_estimators=200,min_samples_leaf=5 ,n_jobs=-1,max_features=0.5)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "submission=sample_submission.copy()\n",
    "submission['status_group'] = model.predict(X_test)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission-011.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_features.astype(float)\n",
    "X_test = test_features.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrislouie/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(20, 40, 60, 40, 20), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(hidden_layer_sizes=(20,40,60,40,20), max_iter=500,\n",
    "                 solver='sgd')\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7957575757575758"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  50785      functional\n",
       "1  51630  non functional\n",
       "2  17168      functional\n",
       "3  45559  non functional\n",
       "4  49871  non functional"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=sample_submission.copy()\n",
    "submission['status_group'] = model.predict(X_test)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission-013.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
