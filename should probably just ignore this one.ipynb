{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrislouie/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error,accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc, recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import warnings\n",
    "import category_encoders as ce\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel,SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression,f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_seq_items = 300\n",
    "pd.options.display.max_rows = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 40), (14358, 40), (59400, 2), (14358, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_features.csv')\n",
    "test_features = pd.read_csv('test_features.csv')\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "train.shape, test_features.shape, train_labels.shape, sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['gps_height'].replace(0.0,np.nan,inplace=True)\n",
    "test_features['gps_height'].replace(0.0,np.nan,inplace=True)\n",
    "train['population'].replace(0.0,np.nan,inplace=True)\n",
    "test_features['population'].replace(0.0,np.nan,inplace=True)\n",
    "train['amount_tsh'].replace(0.0,np.nan,inplace=True)\n",
    "test_features['amount_tsh'].replace(0.0,np.nan,inplace=True)\n",
    "train['latitude'].replace(0.0,np.nan,inplace=True)\n",
    "test_features['latitude'].replace(0.0,np.nan,inplace=True)\n",
    "train['longitude'].replace(0.0,np.nan,inplace=True)\n",
    "test_features['longitude'].replace(0.0,np.nan,inplace=True)\n",
    "train['construction_year'].replace(0.0,np.nan,inplace=True)\n",
    "test_features['construction_year'].replace(0.0,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['construction_year'].fillna(train.groupby(['region', 'district_code'])['construction_year'].transform('median'), inplace=True)\n",
    "train['construction_year'].fillna(train.groupby(['region'])['construction_year'].transform('median'), inplace=True)\n",
    "train['construction_year'].fillna(train.groupby(['district_code'])['construction_year'].transform('median'), inplace=True)\n",
    "train['construction_year'].fillna(train['construction_year'].median(), inplace=True)\n",
    "test_features['construction_year'].fillna(test_features.groupby(['region', 'district_code'])['construction_year'].transform('median'), inplace=True)\n",
    "test_features['construction_year'].fillna(test_features.groupby(['region'])['construction_year'].transform('median'), inplace=True)\n",
    "test_features['construction_year'].fillna(test_features.groupby(['district_code'])['construction_year'].transform('median'), inplace=True)\n",
    "test_features['construction_year'].fillna(test_features['construction_year'].median(), inplace=True)\n",
    "\n",
    "\n",
    "train['age'] = (2019 - train['construction_year']).astype(int)\n",
    "test_features['age'] = (2019 - test_features['construction_year']).astype(int)\n",
    "\n",
    "train_days_since = np.array(train['date_recorded'].values, dtype='datetime64')\n",
    "test_days_since = np.array(test_features['date_recorded'].values,dtype='datetime64')\n",
    "\n",
    "train_birth = round(train['construction_year'])\n",
    "test_birth = round(test_features['construction_year'])\n",
    "\n",
    "train_years_since = np.datetime_as_string(train_days_since, unit='Y')\n",
    "test_years_since = np.datetime_as_string(test_days_since, unit='Y')\n",
    "\n",
    "train_years_since = train_years_since.astype(int)\n",
    "test_years_since = test_years_since.astype(int)\n",
    "\n",
    "in_train_years = []\n",
    "in_test_years = []\n",
    "\n",
    "for i in range(0,len(train_years_since)):\n",
    "    x = train_years_since[i] - train_birth[i]\n",
    "    in_train_years.append(x)\n",
    "    \n",
    "\n",
    "for i in range(0,len(test_years_since)):\n",
    "    x = test_years_since[i] - test_birth[i]\n",
    "    in_test_years.append(x)\n",
    "    \n",
    "train['years_until_record'] = in_train_years\n",
    "test_features['years_until_record'] = in_test_years\n",
    "\n",
    "train_year_record = []\n",
    "test_year_record = []\n",
    "\n",
    "for i in range(0,len(train['construction_year'])):\n",
    "    x = train['construction_year'][i] + train['years_until_record'][i]\n",
    "    train_year_record.append(x)\n",
    "    \n",
    "for i in range(0,len(test_features['construction_year'])):    \n",
    "    x = test_features['construction_year'][i] + test_features['years_until_record'][i]\n",
    "    test_year_record.append(x)\n",
    "    \n",
    "train['year_recorded'] = train_year_record\n",
    "test_features['year_recorded'] = test_year_record\n",
    "\n",
    "train['month'] = train['date_recorded'].apply(lambda x: int(x.split('-')[1]))\n",
    "test_features['month'] = test_features['date_recorded'].apply(lambda x: int(x.split('-')[1]))\n",
    "\n",
    "# https://www.expertafrica.com/tanzania/weather-and-climate\n",
    "\n",
    "def them_seasons(month):\n",
    "    if month in [4,5]:\n",
    "        return 'heavy rain'\n",
    "    elif month in [10, 1, 2]:\n",
    "        return 'humid dry'\n",
    "    elif month == [3,11,12]:\n",
    "        return 'sporadic rain'\n",
    "    elif month in [6,7,8,9]:\n",
    "        return 'cool dry'\n",
    "    else:\n",
    "        return 'some rain'\n",
    "\n",
    "train['season'] = train['month'].apply(them_seasons)\n",
    "test_features['season'] = test_features['month'].apply(them_seasons)\n",
    "\n",
    "train['region_code'] = train['region_code'].astype(str)\n",
    "test_features['region_code'] = test_features['region_code'].astype(str)\n",
    "\n",
    "train['district_code'] = train['district_code'].astype(str)\n",
    "test_features['district_code'] = test_features['district_code'].astype(str)\n",
    "\n",
    "train['population_isnull'] = train['population'] == 0\n",
    "train['subvillage_isnull'] = train['subvillage'].isnull()\n",
    "train['permit_isnull'] = train['permit'].isnull()\n",
    "\n",
    "test_features['population_isnull'] = test_features['population'] == 0\n",
    "test_features['subvillage_isnull'] = test_features['subvillage'].isnull()\n",
    "test_features['permit_isnull'] = test_features['permit'].isnull()\n",
    "\n",
    "train['subvillage'] = train['subvillage'].str.lower()\n",
    "most_sub = train['subvillage'].str.lower().value_counts().index[:30]\n",
    "train['lga'] = train['lga'].str.lower()\n",
    "most_lga = train['lga'].str.lower().value_counts().index[:30]\n",
    "train['wpt_name'] = train['wpt_name'].str.lower()\n",
    "most_wpt = train['wpt_name'].str.lower().value_counts().index[:30]\n",
    "\n",
    "train['subvillage'] = ['other' if sub not in most_sub else sub for sub in \n",
    "                       train['subvillage'].str.lower()]\n",
    "\n",
    "train['lga'] = ['other' if i not in most_lga else i for i in \n",
    "                       train['lga'].str.lower()]\n",
    "\n",
    "train['wpt_name'] = ['other' if wpt not in most_wpt else wpt for wpt in \n",
    "                       train['wpt_name'].str.lower()]\n",
    "\n",
    "train['is_rural'] = [lga.find('rural') != -1 for lga in train['lga']]\n",
    "train['is_urban'] = [lga.find('urban') != -1 for lga in train['lga']]\n",
    "\n",
    "test_features['subvillage'] = test_features['subvillage'].str.lower()\n",
    "most_sub = test_features['subvillage'].str.lower().value_counts().index[:30]\n",
    "test_features['lga'] = test_features['lga'].str.lower()\n",
    "most_lga = test_features['lga'].str.lower().value_counts().index[:30]\n",
    "test_features['wpt_name'] = test_features['wpt_name'].str.lower()\n",
    "most_wpt = test_features['wpt_name'].str.lower().value_counts().index[:30]\n",
    "\n",
    "test_features['subvillage'] = ['other' if sub not in most_sub else sub for sub in \n",
    "                       test_features['subvillage'].str.lower()]\n",
    "\n",
    "test_features['lga'] = ['other' if i not in most_lga else i for i in \n",
    "                       test_features['lga'].str.lower()]\n",
    "\n",
    "test_features['wpt_name'] = ['other' if wpt not in most_wpt else wpt for wpt in \n",
    "                       test_features['wpt_name'].str.lower()]\n",
    "\n",
    "test_features['is_rural'] = [lga.find('rural') != -1 for lga in test_features['lga']]\n",
    "test_features['is_urban'] = [lga.find('urban') != -1 for lga in test_features['lga']]\n",
    "\n",
    "def top_installers(x):\n",
    "    \n",
    "    unknown = ['0', 'unknown'] \n",
    "    government = ['government ', 'government', 'dwe', 'hesawa', 'rwe', 'central government', 'lga',\n",
    "                 'district council', 'gover', 'gove', 'gov', 'district water department',\n",
    "                 'sengerema water department', 'distri', 'centr', 'distric water department',\n",
    "                 'tasaf']\n",
    "    community = ['community', 'commu', 'villagers', 'twesa']    \n",
    "    religious = ['church of disciples', 'kkkt', 'world vision', 'rc church', 'rc', 'tcrs',\n",
    "                'dmdd'] \n",
    "    international = ['norad', 'fini water', 'danida', 'danid', 'ces', 'kuwait',\n",
    "                    'finw']  \n",
    "    private = ['private', 'privat', 'kiliwater', 'wedeco']     \n",
    "    aid = ['roman', 'amref', 'world bank', 'unicef', 'oxfam']\n",
    "    \n",
    "    if x in unknown:\n",
    "        return 'unknown'\n",
    "    \n",
    "    if x in government:\n",
    "        return 'government'\n",
    "\n",
    "    if x in community:\n",
    "        return 'community'\n",
    "\n",
    "    if x in religious:\n",
    "        return 'religious'\n",
    "    \n",
    "    if x in international:\n",
    "        return 'international'\n",
    "\n",
    "    if x in private:\n",
    "        return 'private'\n",
    "\n",
    "    if x in aid:\n",
    "        return 'aid'\n",
    "    \n",
    "    return 'other'\n",
    "\n",
    "def top_funders(x):\n",
    "    \n",
    "    unknown = ['0', 'unknown','no']  \n",
    "    government = ['government ', 'government', 'dwe', 'hesawa', 'rwe', 'central government', 'lga',\n",
    "                 'district council', 'gover', 'gove', 'gov', 'district water department',\n",
    "                 'sengerema water department', 'distri', 'centr', 'distric water department',\n",
    "                 'tasaf', 'government of tanzania','ministry Of water','water','lawatefuka water supply']\n",
    "    community = ['community', 'commu', 'villagers', 'twesa']\n",
    "    religious = ['church of disciples', 'kkkt', 'world vision', 'rc church', 'rc', 'tcrs',\n",
    "                'dmdd','mission','kkkkt_makwale']\n",
    "    international = ['norad', 'fini water', 'danida', 'danid', 'ces', 'kuwait',\n",
    "                    'finw','netherlands','germany republi','jaica','hifab','dwsp',\n",
    "                    'amref','jica','shipo','nethalan', 'swedish']\n",
    "    private = ['private', 'privat', 'kiliwater', 'wedeco']\n",
    "    aid = ['roman', 'amref', 'world bank', 'unicef', 'oxfam','rwssp','wateraid',\n",
    "           'rural water supply and sanitat','adb','oxfarm','dh','rc','go','concern world wide']\n",
    "    if x in unknown:\n",
    "        return 'unknown'\n",
    "    \n",
    "    if x in government:\n",
    "        return 'government'\n",
    "\n",
    "    if x in community:\n",
    "        return 'community'\n",
    "\n",
    "    if x in religious:\n",
    "        return 'religious'\n",
    "    \n",
    "    if x in international:\n",
    "        return 'international'\n",
    "\n",
    "    if x in private:\n",
    "        return 'private'\n",
    "\n",
    "    if x in aid:\n",
    "        return 'aid'\n",
    "    \n",
    "    return 'other'\n",
    "\n",
    "train['funder'] = train['funder'].str.lower().apply(lambda x: top_funders(x))\n",
    "train['installer'] = train['installer'].str.lower().apply(lambda x: top_installers(x))\n",
    "test_features['funder'] = test_features['funder'].str.lower().apply(lambda x: top_funders(x))\n",
    "test_features['installer'] = test_features['installer'].str.lower().apply(lambda x: top_installers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['gps_height'].fillna(train.groupby(['region', 'district_code'])['gps_height'].transform('mean'), inplace=True)\n",
    "train['gps_height'].fillna(train.groupby(['region'])['gps_height'].transform('mean'), inplace=True)\n",
    "train['gps_height'].fillna(train['gps_height'].mean(), inplace=True)\n",
    "train['population'].fillna(train.groupby(['region', 'district_code'])['population'].transform('median'), inplace=True)\n",
    "train['population'].fillna(train.groupby(['region'])['population'].transform('median'), inplace=True)\n",
    "train['population'].fillna(train['population'].median(), inplace=True)\n",
    "train['amount_tsh'].fillna(train.groupby(['region', 'district_code'])['amount_tsh'].transform('median'), inplace=True)\n",
    "train['amount_tsh'].fillna(train.groupby(['region'])['amount_tsh'].transform('median'), inplace=True)\n",
    "train['amount_tsh'].fillna(train['amount_tsh'].median(), inplace=True)\n",
    "train['latitude'].fillna(train.groupby(['region', 'district_code'])['latitude'].transform('mean'), inplace=True)\n",
    "train['longitude'].fillna(train.groupby(['region', 'district_code'])['longitude'].transform('mean'), inplace=True)\n",
    "train['longitude'].fillna(train.groupby(['region'])['longitude'].transform('mean'), inplace=True)\n",
    "\n",
    "test_features['gps_height'].fillna(test_features.groupby(['region', 'district_code'])['gps_height'].transform('mean'), inplace=True)\n",
    "test_features['gps_height'].fillna(test_features.groupby(['region'])['gps_height'].transform('mean'), inplace=True)\n",
    "test_features['gps_height'].fillna(test_features['gps_height'].mean(), inplace=True)\n",
    "test_features['population'].fillna(test_features.groupby(['region', 'district_code'])['population'].transform('median'), inplace=True)\n",
    "test_features['population'].fillna(test_features.groupby(['region'])['population'].transform('median'), inplace=True)\n",
    "test_features['population'].fillna(test_features['population'].median(), inplace=True)\n",
    "test_features['amount_tsh'].fillna(test_features.groupby(['region', 'district_code'])['amount_tsh'].transform('median'), inplace=True)\n",
    "test_features['amount_tsh'].fillna(test_features.groupby(['region'])['amount_tsh'].transform('median'), inplace=True)\n",
    "test_features['amount_tsh'].fillna(test_features['amount_tsh'].median(), inplace=True)\n",
    "test_features['latitude'].fillna(test_features.groupby(['region', 'district_code'])['latitude'].transform('mean'), inplace=True)\n",
    "test_features['longitude'].fillna(test_features.groupby(['region', 'district_code'])['longitude'].transform('mean'), inplace=True)\n",
    "test_features['longitude'].fillna(test_features.groupby(['region'])['longitude'].transform('mean'), inplace=True)\n",
    "\n",
    "train['funder'].fillna('other',inplace=True)\n",
    "train['installer'].fillna('other',inplace=True)\n",
    "train['subvillage'].fillna('other',inplace=True)\n",
    "train['public_meeting'].fillna(False,inplace=True)\n",
    "train['scheme_management'].fillna('None',inplace=True)\n",
    "train['scheme_name'].fillna('None',inplace=True)\n",
    "train['permit'].fillna(False,inplace=True)\n",
    "test_features['funder'].fillna('other',inplace=True)\n",
    "test_features['installer'].fillna('other',inplace=True)\n",
    "test_features['subvillage'].fillna('other',inplace=True)\n",
    "test_features['public_meeting'].fillna(False,inplace=True)\n",
    "test_features['scheme_management'].fillna('None',inplace=True)\n",
    "test_features['scheme_name'].fillna('None',inplace=True)\n",
    "test_features['permit'].fillna(False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 33), (14358, 33))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_these=[\n",
    "    'date_recorded',\n",
    "    'recorded_by',\n",
    "    'ward',\n",
    "    'num_private',\n",
    "    'waterpoint_type_group',\n",
    "    'extraction_type_group',\n",
    "    'extraction_type_class',\n",
    "    'payment_type',\n",
    "    'quality_group',\n",
    "    'quantity_group',\n",
    "    'id',\n",
    "    'source_type',\n",
    "    'source_class',    \n",
    "    'public_meeting',\n",
    "    'scheme_name',\n",
    "    'region',\n",
    "    'management_group'\n",
    "]\n",
    "train.drop(columns=drop_these,inplace=True)\n",
    "test_features.drop(columns=drop_these,inplace=True)\n",
    "\n",
    "train.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.copy()\n",
    "X_test = test_features.copy()\n",
    "y_train = train_labels['status_group']\n",
    "\n",
    "ohe = ce.OneHotEncoder(use_cat_names=True)\n",
    "ohe.fit(X_train,y_train)\n",
    "X_train = ohe.transform(X_train)\n",
    "X_test = ohe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 281), (14358, 281))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(\n",
    "    X_train, y_train_le, test_size = 0.1, stratify=y_train_le,shuffle=True,\n",
    "    random_state= 420\n",
    ")\n",
    "\n",
    "xgb_train = xgb.DMatrix(X_train,label=y_train)\n",
    "xgb_val = xgb.DMatrix(X_val,label=y_val)\n",
    "xgb_test = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.234811\tvalidation-merror:0.26532\n",
      "Multiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation-merror hasn't improved in 25 rounds.\n",
      "[1]\ttrain-merror:0.191414\tvalidation-merror:0.21835\n",
      "[2]\ttrain-merror:0.182061\tvalidation-merror:0.208923\n",
      "[3]\ttrain-merror:0.178994\tvalidation-merror:0.208586\n",
      "[4]\ttrain-merror:0.175889\tvalidation-merror:0.204209\n",
      "[5]\ttrain-merror:0.172278\tvalidation-merror:0.20202\n",
      "[6]\ttrain-merror:0.170296\tvalidation-merror:0.200337\n",
      "[7]\ttrain-merror:0.167995\tvalidation-merror:0.198485\n",
      "[8]\ttrain-merror:0.166255\tvalidation-merror:0.200168\n",
      "[9]\ttrain-merror:0.165208\tvalidation-merror:0.202694\n",
      "[10]\ttrain-merror:0.164198\tvalidation-merror:0.202357\n",
      "[11]\ttrain-merror:0.162495\tvalidation-merror:0.199327\n",
      "[12]\ttrain-merror:0.161504\tvalidation-merror:0.199158\n",
      "[13]\ttrain-merror:0.160868\tvalidation-merror:0.198822\n",
      "[14]\ttrain-merror:0.159521\tvalidation-merror:0.199663\n",
      "[15]\ttrain-merror:0.158305\tvalidation-merror:0.198653\n",
      "[16]\ttrain-merror:0.157127\tvalidation-merror:0.19798\n",
      "[17]\ttrain-merror:0.156828\tvalidation-merror:0.197643\n",
      "[18]\ttrain-merror:0.155743\tvalidation-merror:0.195791\n",
      "[19]\ttrain-merror:0.154733\tvalidation-merror:0.195455\n",
      "[20]\ttrain-merror:0.153498\tvalidation-merror:0.195791\n",
      "[21]\ttrain-merror:0.152712\tvalidation-merror:0.195118\n",
      "[22]\ttrain-merror:0.151852\tvalidation-merror:0.195286\n",
      "[23]\ttrain-merror:0.151085\tvalidation-merror:0.195455\n",
      "[24]\ttrain-merror:0.149813\tvalidation-merror:0.194781\n",
      "[25]\ttrain-merror:0.149476\tvalidation-merror:0.196801\n",
      "[26]\ttrain-merror:0.148447\tvalidation-merror:0.194781\n",
      "[27]\ttrain-merror:0.147681\tvalidation-merror:0.195791\n",
      "[28]\ttrain-merror:0.146558\tvalidation-merror:0.193939\n",
      "[29]\ttrain-merror:0.145585\tvalidation-merror:0.193939\n",
      "[30]\ttrain-merror:0.144725\tvalidation-merror:0.193098\n",
      "[31]\ttrain-merror:0.143958\tvalidation-merror:0.194276\n",
      "[32]\ttrain-merror:0.143285\tvalidation-merror:0.192593\n",
      "[33]\ttrain-merror:0.142368\tvalidation-merror:0.192256\n",
      "[34]\ttrain-merror:0.141264\tvalidation-merror:0.191246\n",
      "[35]\ttrain-merror:0.140629\tvalidation-merror:0.192424\n",
      "[36]\ttrain-merror:0.140367\tvalidation-merror:0.191582\n",
      "[37]\ttrain-merror:0.139151\tvalidation-merror:0.191246\n",
      "[38]\ttrain-merror:0.13829\tvalidation-merror:0.191582\n",
      "[39]\ttrain-merror:0.137673\tvalidation-merror:0.191414\n",
      "[40]\ttrain-merror:0.136756\tvalidation-merror:0.190067\n",
      "[41]\ttrain-merror:0.136289\tvalidation-merror:0.190404\n",
      "[42]\ttrain-merror:0.135503\tvalidation-merror:0.191077\n",
      "[43]\ttrain-merror:0.134961\tvalidation-merror:0.190572\n",
      "[44]\ttrain-merror:0.134343\tvalidation-merror:0.191582\n",
      "[45]\ttrain-merror:0.133764\tvalidation-merror:0.190909\n",
      "[46]\ttrain-merror:0.132623\tvalidation-merror:0.188047\n",
      "[47]\ttrain-merror:0.131612\tvalidation-merror:0.188384\n",
      "[48]\ttrain-merror:0.131444\tvalidation-merror:0.187374\n",
      "[49]\ttrain-merror:0.13049\tvalidation-merror:0.188721\n",
      "[50]\ttrain-merror:0.129929\tvalidation-merror:0.1867\n",
      "[51]\ttrain-merror:0.129012\tvalidation-merror:0.188047\n",
      "[52]\ttrain-merror:0.127965\tvalidation-merror:0.187879\n",
      "[53]\ttrain-merror:0.126768\tvalidation-merror:0.186532\n",
      "[54]\ttrain-merror:0.12587\tvalidation-merror:0.186532\n",
      "[55]\ttrain-merror:0.125571\tvalidation-merror:0.1867\n",
      "[56]\ttrain-merror:0.12514\tvalidation-merror:0.186364\n",
      "[57]\ttrain-merror:0.124542\tvalidation-merror:0.186532\n",
      "[58]\ttrain-merror:0.124336\tvalidation-merror:0.186027\n",
      "[59]\ttrain-merror:0.123401\tvalidation-merror:0.186364\n",
      "[60]\ttrain-merror:0.122465\tvalidation-merror:0.187542\n",
      "[61]\ttrain-merror:0.121717\tvalidation-merror:0.187374\n",
      "[62]\ttrain-merror:0.120857\tvalidation-merror:0.186195\n",
      "[63]\ttrain-merror:0.120239\tvalidation-merror:0.18569\n",
      "[64]\ttrain-merror:0.119903\tvalidation-merror:0.186532\n",
      "[65]\ttrain-merror:0.119379\tvalidation-merror:0.1867\n",
      "[66]\ttrain-merror:0.118837\tvalidation-merror:0.1867\n",
      "[67]\ttrain-merror:0.118294\tvalidation-merror:0.187037\n",
      "[68]\ttrain-merror:0.117752\tvalidation-merror:0.187037\n",
      "[69]\ttrain-merror:0.117247\tvalidation-merror:0.186195\n",
      "[70]\ttrain-merror:0.116685\tvalidation-merror:0.18569\n",
      "[71]\ttrain-merror:0.116386\tvalidation-merror:0.185859\n",
      "[72]\ttrain-merror:0.115619\tvalidation-merror:0.186869\n",
      "[73]\ttrain-merror:0.114964\tvalidation-merror:0.186532\n",
      "[74]\ttrain-merror:0.114328\tvalidation-merror:0.186027\n",
      "[75]\ttrain-merror:0.113936\tvalidation-merror:0.185017\n",
      "[76]\ttrain-merror:0.113244\tvalidation-merror:0.185017\n",
      "[77]\ttrain-merror:0.112907\tvalidation-merror:0.184007\n",
      "[78]\ttrain-merror:0.11214\tvalidation-merror:0.18367\n",
      "[79]\ttrain-merror:0.111392\tvalidation-merror:0.18367\n",
      "[80]\ttrain-merror:0.110625\tvalidation-merror:0.183838\n",
      "[81]\ttrain-merror:0.109783\tvalidation-merror:0.183333\n",
      "[82]\ttrain-merror:0.109184\tvalidation-merror:0.182997\n",
      "[83]\ttrain-merror:0.10881\tvalidation-merror:0.184175\n",
      "[84]\ttrain-merror:0.108623\tvalidation-merror:0.18468\n",
      "[85]\ttrain-merror:0.1081\tvalidation-merror:0.184512\n",
      "[86]\ttrain-merror:0.108006\tvalidation-merror:0.183838\n",
      "[87]\ttrain-merror:0.106902\tvalidation-merror:0.182997\n",
      "[88]\ttrain-merror:0.107164\tvalidation-merror:0.183165\n",
      "[89]\ttrain-merror:0.106322\tvalidation-merror:0.183502\n",
      "[90]\ttrain-merror:0.106004\tvalidation-merror:0.184007\n",
      "[91]\ttrain-merror:0.105556\tvalidation-merror:0.184343\n",
      "[92]\ttrain-merror:0.104751\tvalidation-merror:0.183333\n",
      "[93]\ttrain-merror:0.10419\tvalidation-merror:0.184007\n",
      "[94]\ttrain-merror:0.103722\tvalidation-merror:0.183165\n",
      "[95]\ttrain-merror:0.103442\tvalidation-merror:0.183502\n",
      "[96]\ttrain-merror:0.10303\tvalidation-merror:0.183502\n",
      "[97]\ttrain-merror:0.102525\tvalidation-merror:0.186027\n",
      "[98]\ttrain-merror:0.102114\tvalidation-merror:0.185522\n",
      "[99]\ttrain-merror:0.101908\tvalidation-merror:0.18468\n",
      "[100]\ttrain-merror:0.101758\tvalidation-merror:0.185185\n",
      "[101]\ttrain-merror:0.101496\tvalidation-merror:0.185017\n",
      "[102]\ttrain-merror:0.101272\tvalidation-merror:0.184512\n",
      "[103]\ttrain-merror:0.100935\tvalidation-merror:0.183165\n",
      "[104]\ttrain-merror:0.101029\tvalidation-merror:0.182492\n",
      "[105]\ttrain-merror:0.100412\tvalidation-merror:0.18367\n",
      "[106]\ttrain-merror:0.099757\tvalidation-merror:0.184343\n",
      "[107]\ttrain-merror:0.099532\tvalidation-merror:0.185017\n",
      "[108]\ttrain-merror:0.099252\tvalidation-merror:0.185185\n",
      "[109]\ttrain-merror:0.098653\tvalidation-merror:0.185185\n",
      "[110]\ttrain-merror:0.098597\tvalidation-merror:0.185354\n",
      "[111]\ttrain-merror:0.097886\tvalidation-merror:0.184512\n",
      "[112]\ttrain-merror:0.097793\tvalidation-merror:0.185859\n",
      "[113]\ttrain-merror:0.097512\tvalidation-merror:0.184848\n",
      "[114]\ttrain-merror:0.096783\tvalidation-merror:0.184848\n",
      "[115]\ttrain-merror:0.096577\tvalidation-merror:0.184343\n",
      "[116]\ttrain-merror:0.096165\tvalidation-merror:0.182997\n",
      "[117]\ttrain-merror:0.09624\tvalidation-merror:0.183165\n",
      "[118]\ttrain-merror:0.095585\tvalidation-merror:0.18266\n",
      "[119]\ttrain-merror:0.095604\tvalidation-merror:0.183333\n",
      "[120]\ttrain-merror:0.095043\tvalidation-merror:0.18266\n",
      "[121]\ttrain-merror:0.094482\tvalidation-merror:0.183333\n",
      "[122]\ttrain-merror:0.094632\tvalidation-merror:0.18266\n",
      "[123]\ttrain-merror:0.093977\tvalidation-merror:0.183502\n",
      "[124]\ttrain-merror:0.09379\tvalidation-merror:0.183165\n",
      "[125]\ttrain-merror:0.093434\tvalidation-merror:0.183333\n",
      "[126]\ttrain-merror:0.092742\tvalidation-merror:0.183502\n",
      "[127]\ttrain-merror:0.09248\tvalidation-merror:0.18367\n",
      "[128]\ttrain-merror:0.092275\tvalidation-merror:0.18367\n",
      "[129]\ttrain-merror:0.092555\tvalidation-merror:0.182492\n",
      "Stopping. Best iteration:\n",
      "[104]\ttrain-merror:0.101029\tvalidation-merror:0.182492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {   \n",
    "                 'num_class' : 3,\n",
    "                 'scale_pos_weight' : 1,\n",
    "                 'max_depth': 150,\n",
    "                 'eta': 0.1,\n",
    "                 'n_thread' : 8,\n",
    "                 'colsample_bytree' : 0.5,\n",
    "                 'subsample' : 0.3,\n",
    "                 'silent': 1, \n",
    "                 'n_estimators' : 6000,\n",
    "                 'reg_alpha' : 0.3,\n",
    "                 'gamma' : 1,\n",
    "                 'objective': 'multi:softprob',\n",
    "                 'eval_metric' : 'merror'\n",
    "             } \n",
    "\n",
    "num_rounds = 200\n",
    "\n",
    "evals = [(xgb_train, 'train'), (xgb_val, 'validation')]\n",
    "\n",
    "boost = xgb.train(param_grid, xgb_train, num_rounds, evals, early_stopping_rounds=25)\n",
    "boost.save_model('xgboost_model_1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 8634\n",
       "non functional             5220\n",
       "functional needs repair     504\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = sample_submission.copy()\n",
    "preds = boost.predict(xgb_test)\n",
    "best_preds = le.inverse_transform(np.asarray([np.argmax(x) for x in preds]))\n",
    "submission['status_group'] = best_preds\n",
    "\n",
    "submission['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission-029a.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:27:59] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-merror:0.23324\tvalidation-merror:0.239394\n",
      "Multiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation-merror hasn't improved in 50 rounds.\n",
      "[1]\ttrain-merror:0.180771\tvalidation-merror:0.222896\n",
      "[2]\ttrain-merror:0.17269\tvalidation-merror:0.218687\n",
      "[3]\ttrain-merror:0.169772\tvalidation-merror:0.217003\n",
      "[4]\ttrain-merror:0.1685\tvalidation-merror:0.206734\n",
      "[5]\ttrain-merror:0.167527\tvalidation-merror:0.206734\n",
      "[6]\ttrain-merror:0.165357\tvalidation-merror:0.209428\n",
      "[7]\ttrain-merror:0.162701\tvalidation-merror:0.20505\n",
      "[8]\ttrain-merror:0.159371\tvalidation-merror:0.201684\n",
      "[9]\ttrain-merror:0.157164\tvalidation-merror:0.200505\n",
      "[10]\ttrain-merror:0.155892\tvalidation-merror:0.19697\n",
      "[11]\ttrain-merror:0.1552\tvalidation-merror:0.197475\n",
      "[12]\ttrain-merror:0.154022\tvalidation-merror:0.195623\n",
      "[13]\ttrain-merror:0.153666\tvalidation-merror:0.195791\n",
      "[14]\ttrain-merror:0.152694\tvalidation-merror:0.19596\n",
      "[15]\ttrain-merror:0.150243\tvalidation-merror:0.196296\n",
      "[16]\ttrain-merror:0.150898\tvalidation-merror:0.197643\n",
      "[17]\ttrain-merror:0.149046\tvalidation-merror:0.197811\n",
      "[18]\ttrain-merror:0.148616\tvalidation-merror:0.192929\n",
      "[19]\ttrain-merror:0.146727\tvalidation-merror:0.196296\n",
      "[20]\ttrain-merror:0.14755\tvalidation-merror:0.19596\n",
      "[21]\ttrain-merror:0.14581\tvalidation-merror:0.195118\n",
      "[22]\ttrain-merror:0.145137\tvalidation-merror:0.193771\n",
      "[23]\ttrain-merror:0.143827\tvalidation-merror:0.192761\n",
      "[24]\ttrain-merror:0.141246\tvalidation-merror:0.191919\n",
      "[25]\ttrain-merror:0.143416\tvalidation-merror:0.193939\n",
      "[26]\ttrain-merror:0.142312\tvalidation-merror:0.192929\n",
      "[27]\ttrain-merror:0.143565\tvalidation-merror:0.192761\n",
      "[28]\ttrain-merror:0.140741\tvalidation-merror:0.195286\n",
      "[29]\ttrain-merror:0.140123\tvalidation-merror:0.192424\n",
      "[30]\ttrain-merror:0.14104\tvalidation-merror:0.192761\n",
      "[31]\ttrain-merror:0.138477\tvalidation-merror:0.192424\n",
      "[32]\ttrain-merror:0.139936\tvalidation-merror:0.192088\n",
      "[33]\ttrain-merror:0.137972\tvalidation-merror:0.193603\n",
      "[34]\ttrain-merror:0.138608\tvalidation-merror:0.191246\n",
      "[35]\ttrain-merror:0.13685\tvalidation-merror:0.190909\n",
      "[36]\ttrain-merror:0.137205\tvalidation-merror:0.192256\n",
      "[37]\ttrain-merror:0.13599\tvalidation-merror:0.192256\n",
      "[38]\ttrain-merror:0.134661\tvalidation-merror:0.189731\n",
      "[39]\ttrain-merror:0.134905\tvalidation-merror:0.190236\n",
      "[40]\ttrain-merror:0.13324\tvalidation-merror:0.192256\n",
      "[41]\ttrain-merror:0.133446\tvalidation-merror:0.190404\n",
      "[42]\ttrain-merror:0.133371\tvalidation-merror:0.190741\n",
      "[43]\ttrain-merror:0.130939\tvalidation-merror:0.189057\n",
      "[44]\ttrain-merror:0.132117\tvalidation-merror:0.190404\n",
      "[45]\ttrain-merror:0.130565\tvalidation-merror:0.191077\n",
      "[46]\ttrain-merror:0.130471\tvalidation-merror:0.190404\n",
      "[47]\ttrain-merror:0.131257\tvalidation-merror:0.189226\n",
      "[48]\ttrain-merror:0.128227\tvalidation-merror:0.191246\n",
      "[49]\ttrain-merror:0.128825\tvalidation-merror:0.191919\n",
      "[50]\ttrain-merror:0.128956\tvalidation-merror:0.190741\n",
      "[51]\ttrain-merror:0.129106\tvalidation-merror:0.189731\n",
      "[52]\ttrain-merror:0.127516\tvalidation-merror:0.191077\n",
      "[53]\ttrain-merror:0.128881\tvalidation-merror:0.189394\n",
      "[54]\ttrain-merror:0.12645\tvalidation-merror:0.189394\n",
      "[55]\ttrain-merror:0.127198\tvalidation-merror:0.189899\n",
      "[56]\ttrain-merror:0.126244\tvalidation-merror:0.189731\n",
      "[57]\ttrain-merror:0.125383\tvalidation-merror:0.188889\n",
      "[58]\ttrain-merror:0.124691\tvalidation-merror:0.190067\n",
      "[59]\ttrain-merror:0.124168\tvalidation-merror:0.189562\n",
      "[60]\ttrain-merror:0.123288\tvalidation-merror:0.188384\n",
      "[61]\ttrain-merror:0.122783\tvalidation-merror:0.188384\n",
      "[62]\ttrain-merror:0.122933\tvalidation-merror:0.190572\n",
      "[63]\ttrain-merror:0.119192\tvalidation-merror:0.188889\n",
      "[64]\ttrain-merror:0.121306\tvalidation-merror:0.188047\n",
      "[65]\ttrain-merror:0.123045\tvalidation-merror:0.189562\n",
      "[66]\ttrain-merror:0.120146\tvalidation-merror:0.187879\n",
      "[67]\ttrain-merror:0.118481\tvalidation-merror:0.18771\n",
      "[68]\ttrain-merror:0.118612\tvalidation-merror:0.188889\n",
      "[69]\ttrain-merror:0.119192\tvalidation-merror:0.188889\n",
      "[70]\ttrain-merror:0.117901\tvalidation-merror:0.188384\n",
      "[71]\ttrain-merror:0.117864\tvalidation-merror:0.188889\n",
      "[72]\ttrain-merror:0.120183\tvalidation-merror:0.188552\n",
      "[73]\ttrain-merror:0.118481\tvalidation-merror:0.188047\n",
      "[74]\ttrain-merror:0.116891\tvalidation-merror:0.190067\n",
      "[75]\ttrain-merror:0.11691\tvalidation-merror:0.189562\n",
      "[76]\ttrain-merror:0.118238\tvalidation-merror:0.189394\n",
      "[77]\ttrain-merror:0.115039\tvalidation-merror:0.188721\n",
      "[78]\ttrain-merror:0.115395\tvalidation-merror:0.189899\n",
      "[79]\ttrain-merror:0.111747\tvalidation-merror:0.189562\n",
      "[80]\ttrain-merror:0.113487\tvalidation-merror:0.189226\n",
      "[81]\ttrain-merror:0.113543\tvalidation-merror:0.188552\n",
      "[82]\ttrain-merror:0.113618\tvalidation-merror:0.188384\n",
      "[83]\ttrain-merror:0.115563\tvalidation-merror:0.188215\n",
      "[84]\ttrain-merror:0.111448\tvalidation-merror:0.188215\n",
      "[85]\ttrain-merror:0.114646\tvalidation-merror:0.186364\n",
      "[86]\ttrain-merror:0.112046\tvalidation-merror:0.186869\n",
      "[87]\ttrain-merror:0.111859\tvalidation-merror:0.186364\n",
      "[88]\ttrain-merror:0.111074\tvalidation-merror:0.187879\n",
      "[89]\ttrain-merror:0.11113\tvalidation-merror:0.188215\n",
      "[90]\ttrain-merror:0.1133\tvalidation-merror:0.186869\n",
      "[91]\ttrain-merror:0.1104\tvalidation-merror:0.187542\n",
      "[92]\ttrain-merror:0.111934\tvalidation-merror:0.187374\n",
      "[93]\ttrain-merror:0.108418\tvalidation-merror:0.1867\n",
      "[94]\ttrain-merror:0.108605\tvalidation-merror:0.186027\n",
      "[95]\ttrain-merror:0.106117\tvalidation-merror:0.187037\n",
      "[96]\ttrain-merror:0.109147\tvalidation-merror:0.188889\n",
      "[97]\ttrain-merror:0.109315\tvalidation-merror:0.188215\n",
      "[98]\ttrain-merror:0.108904\tvalidation-merror:0.188384\n",
      "[99]\ttrain-merror:0.109596\tvalidation-merror:0.18771\n",
      "[100]\ttrain-merror:0.108773\tvalidation-merror:0.187374\n",
      "[101]\ttrain-merror:0.107969\tvalidation-merror:0.186364\n",
      "[102]\ttrain-merror:0.108866\tvalidation-merror:0.185859\n",
      "[103]\ttrain-merror:0.108436\tvalidation-merror:0.186195\n",
      "[104]\ttrain-merror:0.107089\tvalidation-merror:0.18569\n",
      "[105]\ttrain-merror:0.108773\tvalidation-merror:0.18367\n",
      "[106]\ttrain-merror:0.106884\tvalidation-merror:0.18771\n",
      "[107]\ttrain-merror:0.104059\tvalidation-merror:0.18569\n",
      "[108]\ttrain-merror:0.106304\tvalidation-merror:0.186195\n",
      "[109]\ttrain-merror:0.108137\tvalidation-merror:0.185185\n",
      "[110]\ttrain-merror:0.105612\tvalidation-merror:0.186532\n",
      "[111]\ttrain-merror:0.104938\tvalidation-merror:0.184512\n",
      "[112]\ttrain-merror:0.10838\tvalidation-merror:0.18468\n",
      "[113]\ttrain-merror:0.105668\tvalidation-merror:0.185859\n",
      "[114]\ttrain-merror:0.104321\tvalidation-merror:0.185859\n",
      "[115]\ttrain-merror:0.103143\tvalidation-merror:0.185522\n",
      "[116]\ttrain-merror:0.103947\tvalidation-merror:0.184848\n",
      "[117]\ttrain-merror:0.108249\tvalidation-merror:0.183502\n",
      "[118]\ttrain-merror:0.105275\tvalidation-merror:0.184848\n",
      "[119]\ttrain-merror:0.103255\tvalidation-merror:0.184512\n",
      "[120]\ttrain-merror:0.102282\tvalidation-merror:0.183838\n",
      "[121]\ttrain-merror:0.102656\tvalidation-merror:0.183838\n",
      "[122]\ttrain-merror:0.104171\tvalidation-merror:0.183333\n",
      "[123]\ttrain-merror:0.10217\tvalidation-merror:0.183838\n",
      "[124]\ttrain-merror:0.102319\tvalidation-merror:0.184007\n",
      "[125]\ttrain-merror:0.10043\tvalidation-merror:0.184848\n",
      "[126]\ttrain-merror:0.102058\tvalidation-merror:0.184512\n",
      "[127]\ttrain-merror:0.103853\tvalidation-merror:0.184175\n",
      "[128]\ttrain-merror:0.10073\tvalidation-merror:0.185354\n",
      "[129]\ttrain-merror:0.101684\tvalidation-merror:0.185522\n",
      "[130]\ttrain-merror:0.099906\tvalidation-merror:0.184007\n",
      "[131]\ttrain-merror:0.101721\tvalidation-merror:0.183333\n",
      "[132]\ttrain-merror:0.099701\tvalidation-merror:0.184512\n",
      "[133]\ttrain-merror:0.100075\tvalidation-merror:0.185185\n",
      "[134]\ttrain-merror:0.099046\tvalidation-merror:0.184343\n",
      "[135]\ttrain-merror:0.100243\tvalidation-merror:0.185185\n",
      "[136]\ttrain-merror:0.099233\tvalidation-merror:0.183838\n",
      "[137]\ttrain-merror:0.098429\tvalidation-merror:0.18367\n",
      "[138]\ttrain-merror:0.099214\tvalidation-merror:0.183838\n",
      "[139]\ttrain-merror:0.098952\tvalidation-merror:0.18468\n",
      "[140]\ttrain-merror:0.099233\tvalidation-merror:0.184007\n",
      "[141]\ttrain-merror:0.098709\tvalidation-merror:0.184343\n",
      "[142]\ttrain-merror:0.09667\tvalidation-merror:0.184343\n",
      "[143]\ttrain-merror:0.098092\tvalidation-merror:0.187205\n",
      "[144]\ttrain-merror:0.100243\tvalidation-merror:0.185017\n",
      "[145]\ttrain-merror:0.097232\tvalidation-merror:0.186364\n",
      "[146]\ttrain-merror:0.096203\tvalidation-merror:0.185185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147]\ttrain-merror:0.098522\tvalidation-merror:0.183502\n",
      "[148]\ttrain-merror:0.098803\tvalidation-merror:0.185185\n",
      "[149]\ttrain-merror:0.097699\tvalidation-merror:0.185185\n",
      "[150]\ttrain-merror:0.097512\tvalidation-merror:0.18569\n",
      "[151]\ttrain-merror:0.095043\tvalidation-merror:0.184848\n",
      "[152]\ttrain-merror:0.096483\tvalidation-merror:0.182828\n",
      "[153]\ttrain-merror:0.094949\tvalidation-merror:0.18468\n",
      "[154]\ttrain-merror:0.09639\tvalidation-merror:0.18468\n",
      "[155]\ttrain-merror:0.095735\tvalidation-merror:0.185354\n",
      "[156]\ttrain-merror:0.095511\tvalidation-merror:0.18367\n",
      "[157]\ttrain-merror:0.098952\tvalidation-merror:0.184512\n",
      "[158]\ttrain-merror:0.097587\tvalidation-merror:0.184007\n",
      "[159]\ttrain-merror:0.094295\tvalidation-merror:0.185017\n",
      "[160]\ttrain-merror:0.094033\tvalidation-merror:0.1867\n",
      "[161]\ttrain-merror:0.093939\tvalidation-merror:0.18468\n",
      "[162]\ttrain-merror:0.093472\tvalidation-merror:0.185017\n",
      "[163]\ttrain-merror:0.095174\tvalidation-merror:0.184512\n",
      "[164]\ttrain-merror:0.092555\tvalidation-merror:0.185522\n",
      "[165]\ttrain-merror:0.093191\tvalidation-merror:0.186532\n",
      "[166]\ttrain-merror:0.09336\tvalidation-merror:0.183333\n",
      "[167]\ttrain-merror:0.092667\tvalidation-merror:0.188047\n",
      "[168]\ttrain-merror:0.093341\tvalidation-merror:0.186532\n",
      "[169]\ttrain-merror:0.093172\tvalidation-merror:0.185354\n",
      "[170]\ttrain-merror:0.093229\tvalidation-merror:0.185354\n",
      "[171]\ttrain-merror:0.09422\tvalidation-merror:0.185354\n",
      "[172]\ttrain-merror:0.093079\tvalidation-merror:0.185859\n",
      "[173]\ttrain-merror:0.094949\tvalidation-merror:0.185354\n",
      "[174]\ttrain-merror:0.092593\tvalidation-merror:0.185859\n",
      "[175]\ttrain-merror:0.092536\tvalidation-merror:0.186027\n",
      "[176]\ttrain-merror:0.092387\tvalidation-merror:0.186364\n",
      "[177]\ttrain-merror:0.093116\tvalidation-merror:0.185859\n",
      "[178]\ttrain-merror:0.092125\tvalidation-merror:0.186195\n",
      "[179]\ttrain-merror:0.094482\tvalidation-merror:0.184848\n",
      "[180]\ttrain-merror:0.092705\tvalidation-merror:0.184848\n",
      "[181]\ttrain-merror:0.092331\tvalidation-merror:0.18771\n",
      "[182]\ttrain-merror:0.09205\tvalidation-merror:0.186195\n",
      "[183]\ttrain-merror:0.094669\tvalidation-merror:0.185354\n",
      "[184]\ttrain-merror:0.092088\tvalidation-merror:0.185185\n",
      "[185]\ttrain-merror:0.092256\tvalidation-merror:0.184848\n",
      "[186]\ttrain-merror:0.092256\tvalidation-merror:0.185354\n",
      "[187]\ttrain-merror:0.092144\tvalidation-merror:0.185859\n",
      "[188]\ttrain-merror:0.091788\tvalidation-merror:0.185859\n",
      "[189]\ttrain-merror:0.092162\tvalidation-merror:0.18468\n",
      "[190]\ttrain-merror:0.09177\tvalidation-merror:0.184343\n",
      "[191]\ttrain-merror:0.091676\tvalidation-merror:0.185522\n",
      "[192]\ttrain-merror:0.090928\tvalidation-merror:0.18367\n",
      "[193]\ttrain-merror:0.09119\tvalidation-merror:0.185017\n",
      "[194]\ttrain-merror:0.093285\tvalidation-merror:0.186532\n",
      "[195]\ttrain-merror:0.092387\tvalidation-merror:0.183838\n",
      "[196]\ttrain-merror:0.091059\tvalidation-merror:0.182997\n",
      "[197]\ttrain-merror:0.091433\tvalidation-merror:0.184343\n",
      "[198]\ttrain-merror:0.093229\tvalidation-merror:0.185185\n",
      "[199]\ttrain-merror:0.093116\tvalidation-merror:0.186364\n",
      "[200]\ttrain-merror:0.090572\tvalidation-merror:0.184007\n",
      "[201]\ttrain-merror:0.090629\tvalidation-merror:0.183838\n",
      "[202]\ttrain-merror:0.089357\tvalidation-merror:0.185185\n",
      "Stopping. Best iteration:\n",
      "[152]\ttrain-merror:0.096483\tvalidation-merror:0.182828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = train.copy()\n",
    "X_test = test_features.copy()\n",
    "y_train = train_labels['status_group']\n",
    "\n",
    "ohe = ce.OneHotEncoder(use_cat_names=True)\n",
    "ohe.fit(X_train,y_train)\n",
    "X_train = ohe.transform(X_train)\n",
    "X_test = ohe.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train.values)\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(\n",
    "    X_train, y_train_le, test_size = 0.1, stratify=y_train_le,shuffle=True,\n",
    "    random_state= 540\n",
    ")\n",
    "\n",
    "xgb_train = xgb.DMatrix(X_train,label=y_train)\n",
    "xgb_val = xgb.DMatrix(X_val,label=y_val)\n",
    "xgb_test = xgb.DMatrix(X_test)\n",
    "\n",
    "param_grid = {   \n",
    "                # spice\n",
    "                 'booster': 'dart',\n",
    "                 'tree_method': 'hist',\n",
    "                 'max_bin': '512',\n",
    "                 'num_class' : 3,\n",
    "                 'scale_pos_weight' : 1,\n",
    "                 'max_depth': 90,\n",
    "                 'eta': 0.1,\n",
    "                 'n_thread' : 8,\n",
    "                 'colsample_bytree' : 0.4,\n",
    "                 'subsample' : 0.5,\n",
    "                 'sample_type': 'weighted',\n",
    "                 'silent': True, \n",
    "                 'n_estimators' : 2000,\n",
    "                 'alpha' : 0.4,\n",
    "                 'gamma' : 1,\n",
    "                 'normalize_type': 'forest',\n",
    "                 'rate_drop': 0.1,\n",
    "                 'skip_drop': 0.5,\n",
    "                 'objective': 'multi:softprob',\n",
    "                 'eval_metric' : 'merror'\n",
    "             } \n",
    "\n",
    "num_rounds = 500\n",
    "\n",
    "evals = [(xgb_train, 'train'), (xgb_val, 'validation')]\n",
    "\n",
    "boost = xgb.train(param_grid, xgb_train, num_rounds, evals, early_stopping_rounds=50)\n",
    "boost.save_model('xgboost_dart_tree_3.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 8607\n",
       "non functional             5270\n",
       "functional needs repair     481\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = sample_submission.copy()\n",
    "preds = boost.predict(xgb_test)\n",
    "best_preds = le.inverse_transform(np.asarray([np.argmax(x) for x in preds]))\n",
    "submission['status_group'] = best_preds\n",
    "\n",
    "submission['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission-031.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=100, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=None,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=2000,\n",
    "                               criterion='gini',\n",
    "                               max_depth=100,\n",
    "                               min_samples_leaf=2,\n",
    "                               oob_score=True)\n",
    "\n",
    "X_train = train.copy()\n",
    "X_test = test_features.copy()\n",
    "y_train = train_labels['status_group']\n",
    "\n",
    "ohe = ce.OneHotEncoder(use_cat_names=True)\n",
    "ohe.fit(X_train,y_train)\n",
    "X_train = ohe.transform(X_train)\n",
    "X_test = ohe.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train.values)\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(\n",
    "    X_train, y_train, test_size = 0.1, stratify=y_train, shuffle=True,\n",
    "    random_state= 540\n",
    ")\n",
    "\n",
    "model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functional                 8970\n",
      "non functional             5015\n",
      "functional needs repair     373\n",
      "Name: status_group, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  50785  non functional\n",
       "1  51630      functional\n",
       "2  17168      functional\n",
       "3  45559  non functional\n",
       "4  49871      functional"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission['status_group'] = model.predict(X_test)\n",
    "print(submission['status_group'].value_counts())\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission-032.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=200, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=4000, n_jobs=None,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=4000,\n",
    "                               criterion='entropy',\n",
    "                               max_depth=200,\n",
    "                               min_samples_leaf=2,\n",
    "                               oob_score=True)\n",
    "\n",
    "X_train = train.copy()\n",
    "X_test = test_features.copy()\n",
    "y_train = train_labels['status_group']\n",
    "\n",
    "ohe = ce.OneHotEncoder(use_cat_names=True)\n",
    "ohe.fit(X_train,y_train)\n",
    "X_train = ohe.transform(X_train)\n",
    "X_test = ohe.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train.values)\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(\n",
    "    X_train, y_train, test_size = 0.1, stratify=y_train, shuffle=True,\n",
    "    random_state= 540\n",
    ")\n",
    "\n",
    "model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functional                 8979\n",
      "non functional             4990\n",
      "functional needs repair     389\n",
      "Name: status_group, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  50785  non functional\n",
       "1  51630      functional\n",
       "2  17168      functional\n",
       "3  45559  non functional\n",
       "4  49871      functional"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission['status_group'] = model.predict(X_test)\n",
    "print(submission['status_group'].value_counts())\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission-032a.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to try feature interaction constraints, and then go ahead\n",
    "# and try stacking\n",
    "\n",
    "# submission-029 == gradient boosting 0.81348\n",
    "# submission-031 == dart 0.81571\n",
    "# submission-032 == randomforest 0.81473\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
