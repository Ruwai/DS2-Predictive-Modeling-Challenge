{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrislouie/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error,accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc, recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import warnings\n",
    "import category_encoders as ce\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel,SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression,f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_seq_items = 300\n",
    "pd.options.display.max_rows = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 40), (14358, 40), (59400, 2), (14358, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_features.csv')\n",
    "test_features = pd.read_csv('test_features.csv')\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "train.shape, test_features.shape, train_labels.shape, sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['gps_height'].replace(0.0,np.nan,inplace=True)\n",
    "test_features['gps_height'].replace(0.0,np.nan,inplace=True)\n",
    "train['population'].replace(0.0,np.nan,inplace=True)\n",
    "test_features['population'].replace(0.0,np.nan,inplace=True)\n",
    "train['amount_tsh'].replace(0.0,np.nan,inplace=True)\n",
    "test_features['amount_tsh'].replace(0.0,np.nan,inplace=True)\n",
    "train['latitude'].replace(0.0,np.nan,inplace=True)\n",
    "test_features['latitude'].replace(0.0,np.nan,inplace=True)\n",
    "train['longitude'].replace(0.0,np.nan,inplace=True)\n",
    "test_features['longitude'].replace(0.0,np.nan,inplace=True)\n",
    "train['construction_year'].replace(0.0,np.nan,inplace=True)\n",
    "test_features['construction_year'].replace(0.0,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['construction_year'].fillna(train.groupby(['region', 'district_code'])['construction_year'].transform('median'), inplace=True)\n",
    "train['construction_year'].fillna(train.groupby(['region'])['construction_year'].transform('median'), inplace=True)\n",
    "train['construction_year'].fillna(train.groupby(['district_code'])['construction_year'].transform('median'), inplace=True)\n",
    "train['construction_year'].fillna(train['construction_year'].median(), inplace=True)\n",
    "test_features['construction_year'].fillna(test_features.groupby(['region', 'district_code'])['construction_year'].transform('median'), inplace=True)\n",
    "test_features['construction_year'].fillna(test_features.groupby(['region'])['construction_year'].transform('median'), inplace=True)\n",
    "test_features['construction_year'].fillna(test_features.groupby(['district_code'])['construction_year'].transform('median'), inplace=True)\n",
    "test_features['construction_year'].fillna(test_features['construction_year'].median(), inplace=True)\n",
    "\n",
    "\n",
    "train['age'] = (2019 - train['construction_year']).astype(int)\n",
    "test_features['age'] = (2019 - test_features['construction_year']).astype(int)\n",
    "\n",
    "train_days_since = np.array(train['date_recorded'].values, dtype='datetime64')\n",
    "test_days_since = np.array(test_features['date_recorded'].values,dtype='datetime64')\n",
    "\n",
    "train_birth = round(train['construction_year'])\n",
    "test_birth = round(test_features['construction_year'])\n",
    "\n",
    "train_years_since = np.datetime_as_string(train_days_since, unit='Y')\n",
    "test_years_since = np.datetime_as_string(test_days_since, unit='Y')\n",
    "\n",
    "train_years_since = train_years_since.astype(int)\n",
    "test_years_since = test_years_since.astype(int)\n",
    "\n",
    "in_train_years = []\n",
    "in_test_years = []\n",
    "\n",
    "for i in range(0,len(train_years_since)):\n",
    "    x = train_years_since[i] - train_birth[i]\n",
    "    in_train_years.append(x)\n",
    "    \n",
    "\n",
    "for i in range(0,len(test_years_since)):\n",
    "    x = test_years_since[i] - test_birth[i]\n",
    "    in_test_years.append(x)\n",
    "    \n",
    "train['years_until_record'] = in_train_years\n",
    "test_features['years_until_record'] = in_test_years\n",
    "\n",
    "train_year_record = []\n",
    "test_year_record = []\n",
    "\n",
    "for i in range(0,len(train['construction_year'])):\n",
    "    x = train['construction_year'][i] + train['years_until_record'][i]\n",
    "    train_year_record.append(x)\n",
    "    \n",
    "for i in range(0,len(test_features['construction_year'])):    \n",
    "    x = test_features['construction_year'][i] + test_features['years_until_record'][i]\n",
    "    test_year_record.append(x)\n",
    "    \n",
    "train['year_recorded'] = train_year_record\n",
    "test_features['year_recorded'] = test_year_record\n",
    "\n",
    "train['month'] = train['date_recorded'].apply(lambda x: int(x.split('-')[1]))\n",
    "test_features['month'] = test_features['date_recorded'].apply(lambda x: int(x.split('-')[1]))\n",
    "\n",
    "# https://www.expertafrica.com/tanzania/weather-and-climate\n",
    "\n",
    "def them_seasons(month):\n",
    "    if month in [4,5]:\n",
    "        return 'heavy rain'\n",
    "    elif month in [10, 1, 2]:\n",
    "        return 'humid dry'\n",
    "    elif month == [3,11,12]:\n",
    "        return 'sporadic rain'\n",
    "    elif month in [6,7,8,9]:\n",
    "        return 'cool dry'\n",
    "    else:\n",
    "        return 'some rain'\n",
    "\n",
    "train['season'] = train['month'].apply(them_seasons)\n",
    "test_features['season'] = test_features['month'].apply(them_seasons)\n",
    "\n",
    "train['region_code'] = train['region_code'].astype(str)\n",
    "test_features['region_code'] = test_features['region_code'].astype(str)\n",
    "\n",
    "train['district_code'] = train['district_code'].astype(str)\n",
    "test_features['district_code'] = test_features['district_code'].astype(str)\n",
    "\n",
    "train['population_isnull'] = train['population'] == 0\n",
    "train['subvillage_isnull'] = train['subvillage'].isnull()\n",
    "train['permit_isnull'] = train['permit'].isnull()\n",
    "\n",
    "test_features['population_isnull'] = test_features['population'] == 0\n",
    "test_features['subvillage_isnull'] = test_features['subvillage'].isnull()\n",
    "test_features['permit_isnull'] = test_features['permit'].isnull()\n",
    "\n",
    "train['subvillage'] = train['subvillage'].str.lower()\n",
    "most_sub = train['subvillage'].str.lower().value_counts().index[:30]\n",
    "train['lga'] = train['lga'].str.lower()\n",
    "most_lga = train['lga'].str.lower().value_counts().index[:30]\n",
    "train['wpt_name'] = train['wpt_name'].str.lower()\n",
    "most_wpt = train['wpt_name'].str.lower().value_counts().index[:30]\n",
    "\n",
    "train['subvillage'] = ['other' if sub not in most_sub else sub for sub in \n",
    "                       train['subvillage'].str.lower()]\n",
    "\n",
    "train['lga'] = ['other' if i not in most_lga else i for i in \n",
    "                       train['lga'].str.lower()]\n",
    "\n",
    "train['wpt_name'] = ['other' if wpt not in most_wpt else wpt for wpt in \n",
    "                       train['wpt_name'].str.lower()]\n",
    "\n",
    "train['is_rural'] = [lga.find('rural') != -1 for lga in train['lga']]\n",
    "train['is_urban'] = [lga.find('urban') != -1 for lga in train['lga']]\n",
    "\n",
    "test_features['subvillage'] = test_features['subvillage'].str.lower()\n",
    "most_sub = test_features['subvillage'].str.lower().value_counts().index[:30]\n",
    "test_features['lga'] = test_features['lga'].str.lower()\n",
    "most_lga = test_features['lga'].str.lower().value_counts().index[:30]\n",
    "test_features['wpt_name'] = test_features['wpt_name'].str.lower()\n",
    "most_wpt = test_features['wpt_name'].str.lower().value_counts().index[:30]\n",
    "\n",
    "test_features['subvillage'] = ['other' if sub not in most_sub else sub for sub in \n",
    "                       test_features['subvillage'].str.lower()]\n",
    "\n",
    "test_features['lga'] = ['other' if i not in most_lga else i for i in \n",
    "                       test_features['lga'].str.lower()]\n",
    "\n",
    "test_features['wpt_name'] = ['other' if wpt not in most_wpt else wpt for wpt in \n",
    "                       test_features['wpt_name'].str.lower()]\n",
    "\n",
    "test_features['is_rural'] = [lga.find('rural') != -1 for lga in test_features['lga']]\n",
    "test_features['is_urban'] = [lga.find('urban') != -1 for lga in test_features['lga']]\n",
    "\n",
    "def top_installers(x):\n",
    "    \n",
    "    unknown = ['0', 'unknown'] \n",
    "    government = ['government ', 'government', 'dwe', 'hesawa', 'rwe', 'central government', 'lga',\n",
    "                 'district council', 'gover', 'gove', 'gov', 'district water department',\n",
    "                 'sengerema water department', 'distri', 'centr', 'distric water department',\n",
    "                 'tasaf']\n",
    "    community = ['community', 'commu', 'villagers', 'twesa']    \n",
    "    religious = ['church of disciples', 'kkkt', 'world vision', 'rc church', 'rc', 'tcrs',\n",
    "                'dmdd'] \n",
    "    international = ['norad', 'fini water', 'danida', 'danid', 'ces', 'kuwait',\n",
    "                    'finw']  \n",
    "    private = ['private', 'privat', 'kiliwater', 'wedeco']     \n",
    "    aid = ['roman', 'amref', 'world bank', 'unicef', 'oxfam']\n",
    "    \n",
    "    if x in unknown:\n",
    "        return 'unknown'\n",
    "    \n",
    "    if x in government:\n",
    "        return 'government'\n",
    "\n",
    "    if x in community:\n",
    "        return 'community'\n",
    "\n",
    "    if x in religious:\n",
    "        return 'religious'\n",
    "    \n",
    "    if x in international:\n",
    "        return 'international'\n",
    "\n",
    "    if x in private:\n",
    "        return 'private'\n",
    "\n",
    "    if x in aid:\n",
    "        return 'aid'\n",
    "    \n",
    "    return 'other'\n",
    "\n",
    "def top_funders(x):\n",
    "    \n",
    "    unknown = ['0', 'unknown','no']  \n",
    "    government = ['government ', 'government', 'dwe', 'hesawa', 'rwe', 'central government', 'lga',\n",
    "                 'district council', 'gover', 'gove', 'gov', 'district water department',\n",
    "                 'sengerema water department', 'distri', 'centr', 'distric water department',\n",
    "                 'tasaf', 'government of tanzania','ministry Of water','water','lawatefuka water supply']\n",
    "    community = ['community', 'commu', 'villagers', 'twesa']\n",
    "    religious = ['church of disciples', 'kkkt', 'world vision', 'rc church', 'rc', 'tcrs',\n",
    "                'dmdd','mission','kkkkt_makwale']\n",
    "    international = ['norad', 'fini water', 'danida', 'danid', 'ces', 'kuwait',\n",
    "                    'finw','netherlands','germany republi','jaica','hifab','dwsp',\n",
    "                    'amref','jica','shipo','nethalan', 'swedish']\n",
    "    private = ['private', 'privat', 'kiliwater', 'wedeco']\n",
    "    aid = ['roman', 'amref', 'world bank', 'unicef', 'oxfam','rwssp','wateraid',\n",
    "           'rural water supply and sanitat','adb','oxfarm','dh','rc','go','concern world wide']\n",
    "    if x in unknown:\n",
    "        return 'unknown'\n",
    "    \n",
    "    if x in government:\n",
    "        return 'government'\n",
    "\n",
    "    if x in community:\n",
    "        return 'community'\n",
    "\n",
    "    if x in religious:\n",
    "        return 'religious'\n",
    "    \n",
    "    if x in international:\n",
    "        return 'international'\n",
    "\n",
    "    if x in private:\n",
    "        return 'private'\n",
    "\n",
    "    if x in aid:\n",
    "        return 'aid'\n",
    "    \n",
    "    return 'other'\n",
    "\n",
    "train['funder'] = train['funder'].str.lower().apply(lambda x: top_funders(x))\n",
    "train['installer'] = train['installer'].str.lower().apply(lambda x: top_installers(x))\n",
    "test_features['funder'] = test_features['funder'].str.lower().apply(lambda x: top_funders(x))\n",
    "test_features['installer'] = test_features['installer'].str.lower().apply(lambda x: top_installers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['gps_height'].fillna(train.groupby(['region', 'district_code'])['gps_height'].transform('mean'), inplace=True)\n",
    "train['gps_height'].fillna(train.groupby(['region'])['gps_height'].transform('mean'), inplace=True)\n",
    "train['gps_height'].fillna(train['gps_height'].mean(), inplace=True)\n",
    "train['population'].fillna(train.groupby(['region', 'district_code'])['population'].transform('median'), inplace=True)\n",
    "train['population'].fillna(train.groupby(['region'])['population'].transform('median'), inplace=True)\n",
    "train['population'].fillna(train['population'].median(), inplace=True)\n",
    "train['amount_tsh'].fillna(train.groupby(['region', 'district_code'])['amount_tsh'].transform('median'), inplace=True)\n",
    "train['amount_tsh'].fillna(train.groupby(['region'])['amount_tsh'].transform('median'), inplace=True)\n",
    "train['amount_tsh'].fillna(train['amount_tsh'].median(), inplace=True)\n",
    "train['latitude'].fillna(train.groupby(['region', 'district_code'])['latitude'].transform('mean'), inplace=True)\n",
    "train['longitude'].fillna(train.groupby(['region', 'district_code'])['longitude'].transform('mean'), inplace=True)\n",
    "train['longitude'].fillna(train.groupby(['region'])['longitude'].transform('mean'), inplace=True)\n",
    "\n",
    "test_features['gps_height'].fillna(test_features.groupby(['region', 'district_code'])['gps_height'].transform('mean'), inplace=True)\n",
    "test_features['gps_height'].fillna(test_features.groupby(['region'])['gps_height'].transform('mean'), inplace=True)\n",
    "test_features['gps_height'].fillna(test_features['gps_height'].mean(), inplace=True)\n",
    "test_features['population'].fillna(test_features.groupby(['region', 'district_code'])['population'].transform('median'), inplace=True)\n",
    "test_features['population'].fillna(test_features.groupby(['region'])['population'].transform('median'), inplace=True)\n",
    "test_features['population'].fillna(test_features['population'].median(), inplace=True)\n",
    "test_features['amount_tsh'].fillna(test_features.groupby(['region', 'district_code'])['amount_tsh'].transform('median'), inplace=True)\n",
    "test_features['amount_tsh'].fillna(test_features.groupby(['region'])['amount_tsh'].transform('median'), inplace=True)\n",
    "test_features['amount_tsh'].fillna(test_features['amount_tsh'].median(), inplace=True)\n",
    "test_features['latitude'].fillna(test_features.groupby(['region', 'district_code'])['latitude'].transform('mean'), inplace=True)\n",
    "test_features['longitude'].fillna(test_features.groupby(['region', 'district_code'])['longitude'].transform('mean'), inplace=True)\n",
    "test_features['longitude'].fillna(test_features.groupby(['region'])['longitude'].transform('mean'), inplace=True)\n",
    "\n",
    "train['funder'].fillna('other',inplace=True)\n",
    "train['installer'].fillna('other',inplace=True)\n",
    "train['subvillage'].fillna('other',inplace=True)\n",
    "train['public_meeting'].fillna(False,inplace=True)\n",
    "train['scheme_management'].fillna('None',inplace=True)\n",
    "train['scheme_name'].fillna('None',inplace=True)\n",
    "train['permit'].fillna(False,inplace=True)\n",
    "test_features['funder'].fillna('other',inplace=True)\n",
    "test_features['installer'].fillna('other',inplace=True)\n",
    "test_features['subvillage'].fillna('other',inplace=True)\n",
    "test_features['public_meeting'].fillna(False,inplace=True)\n",
    "test_features['scheme_management'].fillna('None',inplace=True)\n",
    "test_features['scheme_name'].fillna('None',inplace=True)\n",
    "test_features['permit'].fillna(False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 33), (14358, 33))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_these=[\n",
    "    'date_recorded',\n",
    "    'recorded_by',\n",
    "    'ward',\n",
    "    'num_private',\n",
    "    'waterpoint_type_group',\n",
    "    'extraction_type_group',\n",
    "    'extraction_type_class',\n",
    "    'payment_type',\n",
    "    'quality_group',\n",
    "    'quantity_group',\n",
    "    'id',\n",
    "    'source_type',\n",
    "    'source_class',    \n",
    "    'public_meeting',\n",
    "    'scheme_name',\n",
    "    'region',\n",
    "    'management_group'\n",
    "]\n",
    "train.drop(columns=drop_these,inplace=True)\n",
    "test_features.drop(columns=drop_these,inplace=True)\n",
    "\n",
    "train.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.copy()\n",
    "X_test = test_features.copy()\n",
    "y_train = train_labels['status_group']\n",
    "\n",
    "ohe = ce.OneHotEncoder(use_cat_names=True)\n",
    "ohe.fit(X_train,y_train)\n",
    "X_train = ohe.transform(X_train)\n",
    "X_test = ohe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 281), (14358, 281))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(\n",
    "    X_train, y_train_le, test_size = 0.2, stratify=y_train_le,shuffle=True,\n",
    "    random_state= 369\n",
    ")\n",
    "\n",
    "train = xgb.DMatrix(X_train,label=y_train)\n",
    "val = xgb.DMatrix(X_val,label=y_val)\n",
    "test = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.213152\tvalidation-merror:0.239057\n",
      "Multiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation-merror hasn't improved in 25 rounds.\n",
      "[1]\ttrain-merror:0.194613\tvalidation-merror:0.226094\n",
      "[2]\ttrain-merror:0.186406\tvalidation-merror:0.218687\n",
      "[3]\ttrain-merror:0.183249\tvalidation-merror:0.212542\n",
      "[4]\ttrain-merror:0.180492\tvalidation-merror:0.211111\n",
      "[5]\ttrain-merror:0.180429\tvalidation-merror:0.210438\n",
      "[6]\ttrain-merror:0.177862\tvalidation-merror:0.207323\n",
      "[7]\ttrain-merror:0.173569\tvalidation-merror:0.206145\n",
      "[8]\ttrain-merror:0.173695\tvalidation-merror:0.204966\n",
      "[9]\ttrain-merror:0.171928\tvalidation-merror:0.206229\n",
      "[10]\ttrain-merror:0.170581\tvalidation-merror:0.204798\n",
      "[11]\ttrain-merror:0.170013\tvalidation-merror:0.205219\n",
      "[12]\ttrain-merror:0.16896\tvalidation-merror:0.201936\n",
      "[13]\ttrain-merror:0.167003\tvalidation-merror:0.201263\n",
      "[14]\ttrain-merror:0.165383\tvalidation-merror:0.200253\n",
      "[15]\ttrain-merror:0.16452\tvalidation-merror:0.199242\n",
      "[16]\ttrain-merror:0.163005\tvalidation-merror:0.197811\n",
      "[17]\ttrain-merror:0.162269\tvalidation-merror:0.198148\n",
      "[18]\ttrain-merror:0.161153\tvalidation-merror:0.198401\n",
      "[19]\ttrain-merror:0.160859\tvalidation-merror:0.198064\n",
      "[20]\ttrain-merror:0.16029\tvalidation-merror:0.198485\n",
      "[21]\ttrain-merror:0.159007\tvalidation-merror:0.197306\n",
      "[22]\ttrain-merror:0.157934\tvalidation-merror:0.197306\n",
      "[23]\ttrain-merror:0.155976\tvalidation-merror:0.197138\n",
      "[24]\ttrain-merror:0.155198\tvalidation-merror:0.19798\n",
      "[25]\ttrain-merror:0.153914\tvalidation-merror:0.197391\n",
      "[26]\ttrain-merror:0.152904\tvalidation-merror:0.197222\n",
      "[27]\ttrain-merror:0.151726\tvalidation-merror:0.19596\n",
      "[28]\ttrain-merror:0.150505\tvalidation-merror:0.196212\n",
      "[29]\ttrain-merror:0.149221\tvalidation-merror:0.195707\n",
      "[30]\ttrain-merror:0.148653\tvalidation-merror:0.196044\n",
      "[31]\ttrain-merror:0.147664\tvalidation-merror:0.194024\n",
      "[32]\ttrain-merror:0.147033\tvalidation-merror:0.195118\n",
      "[33]\ttrain-merror:0.145875\tvalidation-merror:0.195286\n",
      "[34]\ttrain-merror:0.145055\tvalidation-merror:0.193771\n",
      "[35]\ttrain-merror:0.143792\tvalidation-merror:0.192929\n",
      "[36]\ttrain-merror:0.143035\tvalidation-merror:0.192929\n",
      "[37]\ttrain-merror:0.142256\tvalidation-merror:0.192172\n",
      "[38]\ttrain-merror:0.141014\tvalidation-merror:0.191498\n",
      "[39]\ttrain-merror:0.140614\tvalidation-merror:0.192003\n",
      "[40]\ttrain-merror:0.13952\tvalidation-merror:0.191582\n",
      "[41]\ttrain-merror:0.138615\tvalidation-merror:0.190993\n",
      "[42]\ttrain-merror:0.137416\tvalidation-merror:0.190825\n",
      "[43]\ttrain-merror:0.136258\tvalidation-merror:0.190572\n",
      "[44]\ttrain-merror:0.135375\tvalidation-merror:0.190152\n",
      "[45]\ttrain-merror:0.134596\tvalidation-merror:0.19032\n",
      "[46]\ttrain-merror:0.134133\tvalidation-merror:0.189815\n",
      "[47]\ttrain-merror:0.133228\tvalidation-merror:0.189731\n",
      "[48]\ttrain-merror:0.132597\tvalidation-merror:0.189562\n",
      "[49]\ttrain-merror:0.132239\tvalidation-merror:0.188805\n",
      "[50]\ttrain-merror:0.131334\tvalidation-merror:0.188215\n",
      "[51]\ttrain-merror:0.130492\tvalidation-merror:0.189057\n",
      "[52]\ttrain-merror:0.129588\tvalidation-merror:0.189057\n",
      "[53]\ttrain-merror:0.128767\tvalidation-merror:0.189646\n",
      "[54]\ttrain-merror:0.12763\tvalidation-merror:0.18931\n",
      "[55]\ttrain-merror:0.127378\tvalidation-merror:0.188973\n",
      "[56]\ttrain-merror:0.126684\tvalidation-merror:0.190572\n",
      "[57]\ttrain-merror:0.125758\tvalidation-merror:0.189394\n",
      "[58]\ttrain-merror:0.124979\tvalidation-merror:0.188721\n",
      "[59]\ttrain-merror:0.124537\tvalidation-merror:0.189226\n",
      "[60]\ttrain-merror:0.123674\tvalidation-merror:0.188805\n",
      "[61]\ttrain-merror:0.123485\tvalidation-merror:0.188636\n",
      "[62]\ttrain-merror:0.122327\tvalidation-merror:0.187795\n",
      "[63]\ttrain-merror:0.121296\tvalidation-merror:0.188131\n",
      "[64]\ttrain-merror:0.12056\tvalidation-merror:0.188805\n",
      "[65]\ttrain-merror:0.119802\tvalidation-merror:0.187879\n",
      "[66]\ttrain-merror:0.119129\tvalidation-merror:0.188047\n",
      "[67]\ttrain-merror:0.118771\tvalidation-merror:0.187458\n",
      "[68]\ttrain-merror:0.117445\tvalidation-merror:0.187542\n",
      "[69]\ttrain-merror:0.11673\tvalidation-merror:0.187121\n",
      "[70]\ttrain-merror:0.115699\tvalidation-merror:0.1867\n",
      "[71]\ttrain-merror:0.115446\tvalidation-merror:0.186448\n",
      "[72]\ttrain-merror:0.115173\tvalidation-merror:0.1867\n",
      "[73]\ttrain-merror:0.114541\tvalidation-merror:0.186532\n",
      "[74]\ttrain-merror:0.114247\tvalidation-merror:0.186616\n",
      "[75]\ttrain-merror:0.113005\tvalidation-merror:0.18729\n",
      "[76]\ttrain-merror:0.113258\tvalidation-merror:0.187121\n",
      "[77]\ttrain-merror:0.112879\tvalidation-merror:0.187374\n",
      "[78]\ttrain-merror:0.112542\tvalidation-merror:0.187205\n",
      "[79]\ttrain-merror:0.111742\tvalidation-merror:0.186785\n",
      "[80]\ttrain-merror:0.111385\tvalidation-merror:0.187037\n",
      "[81]\ttrain-merror:0.110985\tvalidation-merror:0.186279\n",
      "[82]\ttrain-merror:0.110564\tvalidation-merror:0.187037\n",
      "[83]\ttrain-merror:0.110185\tvalidation-merror:0.187205\n",
      "[84]\ttrain-merror:0.109196\tvalidation-merror:0.186869\n"
     ]
    }
   ],
   "source": [
    "param_grid = {   \n",
    "                 'num_class' : 3,\n",
    "                 'scale_pos_weight' : 1,\n",
    "                 'max_depth': 80, # very deep tree\n",
    "                 'eta': 0.1,\n",
    "                 'n_thread' : 8,\n",
    "                 'colsample_bytree' : 0.5,\n",
    "                 'subsample' : 0.3,\n",
    "                 'silent': 1, \n",
    "                 'n_estimators' : 4000, # lots of estimators\n",
    "                 'reg_alpha' : 0.3,\n",
    "                 'gamma' : 1,\n",
    "                 'objective': 'multi:softprob',\n",
    "                 'eval_metric' : 'merror'\n",
    "             } \n",
    "\n",
    "num_rounds = 200\n",
    "\n",
    "evals = [(train, 'train'), (val, 'validation')]\n",
    "\n",
    "boost = xgb.train(param_grid, train, num_rounds, evals, early_stopping_rounds=25)\n",
    "boost.save_model('xgboost_model_1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
