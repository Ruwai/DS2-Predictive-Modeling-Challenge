{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrislouie/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import warnings\n",
    "import category_encoders as ce\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression,f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 40), (14358, 40), (59400, 2), (14358, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = pd.read_csv('train_features.csv')\n",
    "test_features = pd.read_csv('test_features.csv')\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "train_features.shape, test_features.shape, train_labels.shape, sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_mean = train[train['construction_year']>0]['construction_year'].mean()\n",
    "year_mean = round(year_mean)\n",
    "\n",
    "test_year_mean = test_features[test_features['construction_year']>0]['construction_year'].mean()\n",
    "test_year_mean = round(test_year_mean)\n",
    "\n",
    "\n",
    "train.loc[train['construction_year']==0, 'construction_year'] = int(year_mean)\n",
    "test_features.loc[test_features['construction_year']==0,'construction_year'] = int(test_year_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_std(year):\n",
    "\n",
    "    return year - random.randint(-10,10)\n",
    "\n",
    "def random_tsh(amount):\n",
    "\n",
    "    return amount + random.uniform(-1062.35, 1957.82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-225.45916350815708"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tsh(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tsh_mean = train[train['amount_tsh']>0]['amount_tsh'].mean()\n",
    "test_tsh_mean = test_features[test_features['amount_tsh']>0]['amount_tsh'].mean()\n",
    "\n",
    "train.loc[train['amount_tsh']==0,'amount_tsh']=float(train_tsh_mean)\n",
    "test_features.loc[test_features['amount_tsh']==0,'amount_tsh']=float(test_tsh_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[train['construction_year']==1997,'construction_year'].apply(random_std(),axis=1)\n",
    "# test_features.loc[test_features['construction_year']==1997,'construction_year'].apply(random_std(),axis=1)\n",
    "# train.loc[train['amount_tsh']==train_tsh_mean, 'amount_tsh'].apply(random_tsh(),axis=1)\n",
    "# test_features.loc[test_features['amount_tsh']==test_tsh_mean, 'amount_tsh'].apply(random_tsh(),axis=1)\n",
    "\n",
    "# train.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[train['construction_year']==1997,'construction_year'].apply(random_std)\n",
    "# test_features.loc[test_features['construction_year']==1997,'construction_year'].transform(random_std)\n",
    "# train.loc[train['amount_tsh']==train_tsh_mean, 'amount_tsh'].transform(random_tsh)\n",
    "# test_features.loc[test_features['amount_tsh']==test_tsh_mean, 'amount_tsh'].transform(random_tsh)\n",
    "\n",
    "# train.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>installer</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>region</th>\n",
       "      <th>lga</th>\n",
       "      <th>ward</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>recorded_by</th>\n",
       "      <th>scheme_management</th>\n",
       "      <th>scheme_name</th>\n",
       "      <th>permit</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>extraction_type_group</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59400</td>\n",
       "      <td>55765</td>\n",
       "      <td>55745</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59029</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>56066</td>\n",
       "      <td>59400</td>\n",
       "      <td>55523</td>\n",
       "      <td>31234</td>\n",
       "      <td>56344</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "      <td>59400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>356</td>\n",
       "      <td>1897</td>\n",
       "      <td>2145</td>\n",
       "      <td>37400</td>\n",
       "      <td>9</td>\n",
       "      <td>19287</td>\n",
       "      <td>21</td>\n",
       "      <td>125</td>\n",
       "      <td>2092</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2696</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2011-03-15</td>\n",
       "      <td>Government Of Tanzania</td>\n",
       "      <td>DWE</td>\n",
       "      <td>none</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Madukani</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>Njombe</td>\n",
       "      <td>Igosi</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>K</td>\n",
       "      <td>True</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>572</td>\n",
       "      <td>9084</td>\n",
       "      <td>17402</td>\n",
       "      <td>3563</td>\n",
       "      <td>10248</td>\n",
       "      <td>508</td>\n",
       "      <td>5294</td>\n",
       "      <td>2503</td>\n",
       "      <td>307</td>\n",
       "      <td>51011</td>\n",
       "      <td>59400</td>\n",
       "      <td>36793</td>\n",
       "      <td>682</td>\n",
       "      <td>38852</td>\n",
       "      <td>26780</td>\n",
       "      <td>26780</td>\n",
       "      <td>26780</td>\n",
       "      <td>40507</td>\n",
       "      <td>52490</td>\n",
       "      <td>25348</td>\n",
       "      <td>25348</td>\n",
       "      <td>50818</td>\n",
       "      <td>50818</td>\n",
       "      <td>33186</td>\n",
       "      <td>33186</td>\n",
       "      <td>17021</td>\n",
       "      <td>17021</td>\n",
       "      <td>45794</td>\n",
       "      <td>28522</td>\n",
       "      <td>34625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_recorded                  funder installer wpt_name  \\\n",
       "count          59400                   55765     55745    59400   \n",
       "unique           356                    1897      2145    37400   \n",
       "top       2011-03-15  Government Of Tanzania       DWE     none   \n",
       "freq             572                    9084     17402     3563   \n",
       "\n",
       "                basin subvillage  region     lga   ward public_meeting  \\\n",
       "count           59400      59029   59400   59400  59400          56066   \n",
       "unique              9      19287      21     125   2092              2   \n",
       "top     Lake Victoria   Madukani  Iringa  Njombe  Igosi           True   \n",
       "freq            10248        508    5294    2503    307          51011   \n",
       "\n",
       "                    recorded_by scheme_management scheme_name permit  \\\n",
       "count                     59400             55523       31234  56344   \n",
       "unique                        1                12        2696      2   \n",
       "top     GeoData Consultants Ltd               VWC           K   True   \n",
       "freq                      59400             36793         682  38852   \n",
       "\n",
       "       extraction_type extraction_type_group extraction_type_class management  \\\n",
       "count            59400                 59400                 59400      59400   \n",
       "unique              18                    13                     7         12   \n",
       "top            gravity               gravity               gravity        vwc   \n",
       "freq             26780                 26780                 26780      40507   \n",
       "\n",
       "       management_group    payment payment_type water_quality quality_group  \\\n",
       "count             59400      59400        59400         59400         59400   \n",
       "unique                5          7            7             8             6   \n",
       "top          user-group  never pay    never pay          soft          good   \n",
       "freq              52490      25348        25348         50818         50818   \n",
       "\n",
       "       quantity quantity_group  source source_type source_class  \\\n",
       "count     59400          59400   59400       59400        59400   \n",
       "unique        5              5      10           7            3   \n",
       "top      enough         enough  spring      spring  groundwater   \n",
       "freq      33186          33186   17021       17021        45794   \n",
       "\n",
       "           waterpoint_type waterpoint_type_group  \n",
       "count                59400                 59400  \n",
       "unique                   7                     6  \n",
       "top     communal standpipe    communal standpipe  \n",
       "freq                 28522                 34625  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(exclude=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['funder'].fillna('?',inplace=True)\n",
    "train['installer'].fillna('?',inplace=True)\n",
    "train['subvillage'].fillna('?',inplace=True)\n",
    "train['public_meeting'].fillna('?',inplace=True)\n",
    "train['scheme_management'].fillna('?',inplace=True)\n",
    "train['scheme_name'].fillna('?',inplace=True)\n",
    "train['permit'].fillna('?',inplace=True)\n",
    "test_features['funder'].fillna('?',inplace=True)\n",
    "test_features['installer'].fillna('?',inplace=True)\n",
    "test_features['subvillage'].fillna('?',inplace=True)\n",
    "test_features['public_meeting'].fillna('?',inplace=True)\n",
    "test_features['scheme_management'].fillna('?',inplace=True)\n",
    "test_features['scheme_name'].fillna('?',inplace=True)\n",
    "test_features['permit'].fillna('?',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['age'] = (2019 - train['construction_year']).astype(int)\n",
    "test_features['age'] = (2019 - test_features['construction_year']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_days_since = np.array(train['date_recorded'].values, dtype='datetime64')\n",
    "test_days_since = np.array(test_features['date_recorded'].values,dtype='datetime64')\n",
    "\n",
    "train_birth = train['construction_year'].astype(str)\n",
    "test_birth = test_features['construction_year'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years_since = np.datetime_as_string(train_days_since, unit='Y')\n",
    "test_years_since = np.datetime_as_string(test_days_since, unit='Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years_since = train_years_since.astype(int)\n",
    "test_years_since = test_years_since.astype(int)\n",
    "train_birth = train_birth.astype(int)\n",
    "test_birth = test_birth.astype(int)\n",
    "\n",
    "in_train_years = []\n",
    "in_test_years = []\n",
    "\n",
    "for i in range(0,len(train_years_since)):\n",
    "    x = train_years_since[i] - train_birth[i]\n",
    "    in_train_years.append(x)\n",
    "    \n",
    "\n",
    "for i in range(0,len(test_years_since)):\n",
    "    x = test_years_since[i] - test_birth[i]\n",
    "    in_test_years.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['years_until_record'] = in_train_years\n",
    "test_features['years_until_record'] = in_test_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 24), (14358, 24))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_these=[\n",
    "    'date_recorded',\n",
    "    'wpt_name',\n",
    "    'recorded_by',\n",
    "    'lga',\n",
    "    'ward',\n",
    "    'scheme_name', \n",
    "    'scheme_management',\n",
    "    'funder',\n",
    "    'installer',\n",
    "    'num_private',\n",
    "    'subvillage',\n",
    "    'basin',\n",
    "    'longitude',\n",
    "    'latitude',\n",
    "    'waterpoint_type_group',\n",
    "    'extraction_type_group',\n",
    "    'extraction_type_class',\n",
    "    'management_group', \n",
    "]\n",
    "train.drop(columns=drop_these,inplace=True)\n",
    "test_features.drop(columns=drop_these,inplace=True)\n",
    "\n",
    "train.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_cols = train.select_dtypes(include=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashing = ce.HashingEncoder(\n",
    "#     cols = list(str_cols.columns),\n",
    "#     verbose=1,\n",
    "#     drop_invariant=True,\n",
    "#     return_df=True,\n",
    "# )\n",
    "\n",
    "# train_features = hashing.fit_transform(train)\n",
    "# test_features = hashing.fit_transform(test_features)\n",
    "\n",
    "# train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 24), (14358, 24))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe = ce.OrdinalEncoder(verbose=1,mapping=None,cols=None,drop_invariant=True,\n",
    "                       return_df=True, impute_missing=True,handle_unknown='ignore')\n",
    "\n",
    "train_features = oe.fit_transform(train)\n",
    "test_features = oe.fit_transform(test_features)\n",
    "\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  8.3min finished\n",
      "/Users/chrislouie/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_bin=512,\n",
       "        max_depth=-1, min_child_samples=25, min_child_weight=1,\n",
       "        min_split_gain=0.5, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "        objective='multiclass', random_state=None, reg_alpha=0.0,\n",
       "        reg_lambda=0.0, silent=True, subsample=1, subsample_for_bin=100000,\n",
       "        subsample_freq=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'boosting_type': ['gbdt'], 'learning_rate': [0.001, 0.01], 'num_iterations': [1000, 2000], 'num_leaves': [100, 200], 'min_child_samples': [50], 'subsample_for_bin': [200000], 'reg_alpha': [1.2], 'reg_lambda': [1.2], 'min_split_gain': [0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_features\n",
    "X_test = test_features\n",
    "y_train = train_labels['status_group']\n",
    "scaler = RobustScaler()\n",
    "X_train = X_train.drop(columns='id')\n",
    "X_test = X_test.drop(columns='id')\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'multiclass',\n",
    "          'num_leaves': 42,\n",
    "          'learning_rate': 0.01,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 100000,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 2,\n",
    "          'reg_lambda': 5,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 25,\n",
    "          'num_class' : 3,\n",
    "          'metric' : 'multi_logloss'}\n",
    "\n",
    "model = lgb.LGBMClassifier(\n",
    "    boosting_type = 'gbdt',\n",
    "    objective = 'multiclass',\n",
    "    n_jobs = -1,\n",
    "    max_depth = params['max_depth'],\n",
    "    max_bin = params['max_bin'],\n",
    "    subsample_for_bin = params['subsample_for_bin'],\n",
    "    subsample = params['subsample'],\n",
    "    subsample_freq = params['subsample_freq'],\n",
    "    min_split_gain = params['min_split_gain'],\n",
    "    min_child_weight = params['min_child_weight'],\n",
    "    min_child_samples = params['min_child_samples'],\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'learning_rate': [0.001,0.01],\n",
    "    'num_iterations': [1000,2000],\n",
    "    'num_leaves': [100,200],\n",
    "    'min_child_samples': [50],\n",
    "    'subsample_for_bin': [200000],    \n",
    "    'reg_alpha': [1.2],\n",
    "    'reg_lambda': [1.2],\n",
    "    'min_split_gain': [0.5]\n",
    "}\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     'boosting_type': ['gbdt', 'dart'],\n",
    "#     'learning_rate': [0.001,0.01],\n",
    "#     'num_iterations': [1000,2000],\n",
    "#     'num_leaves': [100,200],\n",
    "#     'min_child_samples': [25,50],\n",
    "#     'subsample_for_bin': [200000],    \n",
    "#     'reg_alpha': [1.2],\n",
    "#     'reg_lambda': [1.2],\n",
    "#     'min_split_gain': [0.5]\n",
    "# }\n",
    "# hopefully this works lol\n",
    "gridsearch = GridSearchCV(model, param_grid = param_grid,\n",
    "                          verbose=1,cv=3,n_jobs=-1,scoring='accuracy')\n",
    "\n",
    "gridsearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'learning_rate': 0.01,\n",
       " 'min_child_samples': 50,\n",
       " 'min_split_gain': 0.5,\n",
       " 'num_iterations': 1000,\n",
       " 'num_leaves': 200,\n",
       " 'reg_alpha': 1.2,\n",
       " 'reg_lambda': 1.2,\n",
       " 'subsample_for_bin': 200000}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7845117845117845"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['learning_rate'] = gridsearch.best_params_['learning_rate']\n",
    "params['num_leaves'] = gridsearch.best_params_['num_leaves']\n",
    "params['num_iterations'] = gridsearch.best_params_['num_iterations']\n",
    "params['subsample_for_bin'] = gridsearch.best_params_['subsample_for_bin']\n",
    "params['min_child_samples'] = gridsearch.best_params_['min_child_samples']\n",
    "params['reg_alpha'] = gridsearch.best_params_['reg_alpha']\n",
    "params['reg_lambda'] = gridsearch.best_params_['reg_lambda']\n",
    "params['min_split_gain'] = gridsearch.best_params_['min_split_gain']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  50785  non functional\n",
       "1  51630      functional\n",
       "2  17168      functional\n",
       "3  45559  non functional\n",
       "4  49871      functional"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=sample_submission.copy()\n",
    "submission['status_group'] = gridsearch.predict(X_test)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission-015.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
